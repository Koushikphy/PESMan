#!/usr/bin/python
# -*- coding: utf-8 -*-

import sqlite3
import os
import sys
import os.path
import shutil
#import tempfile
import geometry
import misc
import re
import subprocess
#import hyper
import bisect

# the following sql commands creates tables used by manager
# fields to be documented soon
sql_table_commands = """
BEGIN TRANSACTION;
CREATE TABLE Geometry(
Id INTEGER PRIMARY KEY,
Rho REAL,
Theta REAL,
Phi REAL,
Tags TEXT,
Desc TEXT);
CREATE TABLE CalcInfo(
Id INTEGER PRIMARY KEY,
Type TEXT NOT NULL,
Name TEXT NOT NULL,
Depends INTEGER NOT NULL,
InpTempl TEXT NOT NULL,
OrbRec TEXT NOT NULL,
ResVars TEXT NOT NULL,
Desc TEXT);
CREATE TABLE Calc(
Id INTEGER PRIMARY KEY,
GeomId INTEGER NOT NULL,
CalcId INTEGER NOT NULL,
Dir TEXT NOT NULL,
WfnFile TEXT NOT NULL,
OrbRec TEXT NOT NULL,
InputFile TEXT NOT NULL,
OutputFile TEXT NOT NULL,
ResultFile TEXT NOT NULL,
AuxFiles TEXT,
Results TEXT,
Desc TEXT);
END TRANSACTION;
"""

def create_tables(dbfile,sql_script):

   assert (dbfile)
   assert (sql_script)
   assert (isinstance(dbfile, basestring) and isinstance(sql_script,basestring))
   assert (not os.path.exists(dbfile)) # dbfile must not exist

   # now open db file, this will create the new data base

   con = None
   try:
      con = sqlite3.connect(dbfile)
      cur = con.cursor()  
      cur.executescript(sql_script)
      con.commit()

   except sqlite3.Error, e:
      if con:
        print e
        con.rollback()
      sys.exit(1)

   except:
      print('Unknown error')
      raise

   finally:
      if con:
        con.close() 

   return

def GenCalcFile(CalcId,GeomId,CalcName,Record,Basename,Desc="",Aux=""):

    sheader = """
# This file is automatically generated.
# The defaults are usually sufficient for import.
# Do not edit, unless you are sure of what you are changing.
#
"""
    scalc = "CalcId   : " + str(CalcId)
    sgeom = "GeomId   : " + str(GeomId)
    sname = "Name     : " + str(CalcName)
    srec  = "Record   : " + str(Record)
    sbase = "Basename : " + str(Basename)
    sdesc = "Desc     : " + str(Desc)
    saux  = "Aux      : " + str(Aux)

    return "\n".join([sheader,scalc,sgeom,sname,srec,sbase,sdesc,saux]) + "\n"

def ParseFile(sfile,lkeys):
   """ A generic parser which can parse key : value pairs from any string and return a dictionary of parsed options """
   def remove_comments(s):
       p = s.find("#")
       if p >=0:
          snew = s[0:p]
       else:
          snew = s
       return snew.strip()
   ls0 = [x.strip() for x in sfile.splitlines() if x.strip()]
   ls1 = [tuple(x.split(":")) for x in ls0 if remove_comments(x)]
   for t in ls1:
      assert (len(t) == 2)
   ls2 = [(x.strip(),y.strip()) for (x,y) in ls1]
   lparse = { k.upper():v for (k,v) in ls2 }
   for key in lkeys:
      assert( key.upper() in lparse )
   assert (len(lparse) == len(lkeys))
   return lparse


def GetResults(sres,fres):
    """ Grep the results from results file and return a tuple """
    lres = sres.split()
    with open(fres,'r') as f:
       sfile = f.read()
       f.close()
    lmatch = []
    for sr in lres:
      r = re.compile(sr + '\s+([-+]?[0-9]*\.[0-9]+)')
      sg = r.search(sfile)
      if sg:
         # match found
         lmatch.append(sg.group(1))
      else:
         # do not try to find some match for now
         #raise Exception("Match not found" + sr + "in file" + fres)
         pass
    return " ".join(lmatch)

def AddNewCalcType(db,conf):
   """ Add a new calculation type into the database
       db    -- data base file
       conf  -- config file specifying the calculation
       NOTE : all file names must be fully qualified. they are simply opened.
   """
   # first parse the conf files
   templ = None
   misc.CheckFileAccess(conf,True,True)
   with open(conf,'r') as f:
      sconf = f.read()
      f.close()
      tconf = ParseFile(sconf,["name","type","depends","template","record","resvars","desc"])
      # checks on the sanity of config file
      tconf["NAME"] = tconf["NAME"].lower()
      tconf["TYPE"] = tconf["TYPE"].lower()
      assert (tconf["TYPE"] in ["multi", "mrci", "multinact"])
      tconf["DEPENDS"] = tconf["DEPENDS"].lower()
      assert (tconf["DEPENDS"] == "none" or tconf["DEPENDS"].isdigit())
      if tconf["DEPENDS"] == "none":
         tconf["DEPENDS"] = 0
      else:
         tconf["DEPENDS"] = int(tconf["DEPENDS"])
      templ = tconf["TEMPLATE"]
      assert(templ)
      lrec = tconf["RECORD"].split(".",1)
      assert (len(lrec) == 2 and lrec[0].isdigit() and lrec[1].isdigit())
      rec,fil = int(lrec[0]),int(lrec[1])
      tconf["RECORD"] = str(rec) + "." + str(fil)
      # desc and resvars are unchanged, used later

   # open templ file defined previously
   misc.CheckFileAccess(templ,bRead=True,bAssert=True)
   with open(templ,'r') as f:
      stemp = f.read()
      f.close()

   # now we are ready to open the data base and add record to CalcInfo table
   misc.CheckFileAccess(db,bRead=True,bAssert=True)
   with sqlite3.connect(db) as con:
      # define cursor, data base opening errors are taken care automatically
      cur = con.cursor()
      for n in cur.execute('SELECT Name from CalcInfo'):
         assert( tconf["NAME"] != n[0] )
      tcalc = (tconf["TYPE"],tconf["NAME"],tconf["DEPENDS"],stemp,tconf["RECORD"],tconf["RESVARS"],tconf["DESC"])
      cur.execute("""INSERT INTO CalcInfo (Type,Name,Depends,InpTempl,OrbRec,ResVars,Desc) VALUES (?, ?, ?, ?, ?, ?, ?)""", tcalc)
      # now we are done, release
      con.commit()
      # check if it is inserted properly
      for row in cur.execute("SELECT * FROM CalcInfo"):
         print row
      print "record inserted and closed"

      # works!

def ImportCalc(Db,CalcDir,CalcFile,DestBaseDir,Verbose=False):
   """ Import the results of a calculation.
       Db       -- data base to import into
       CalcDir  -- directory where the results of calculation can be found
       CalcFile -- the .calc file of the calculation from which information is collected.
                   NOTE : you may also modify .calc to make necessary changes,
                          such as altering the record number where orbitals are stored
                          adding notes and further files to be copied etc,.
       DestBaseDir  -- the directory where the results should be copied to.
   """

   # CalcDir should have read access
   # CalcFile should have read access
   # DestBaseDir must have write access
   misc.CheckDirAccess(CalcDir,bRead=True,bAssert=True)
   misc.CheckFileAccess(CalcFile,bRead=True,bAssert=True)
   misc.CheckDirAccess(DestBaseDir,bRead=False,bAssert=True)

   # Db must have read as well as write access
   misc.CheckFileAccess(Db,bRead=True,bAssert=True)
   misc.CheckFileAccess(Db,bRead=False,bAssert=True)

   # parse calcfile and get basename
   # this is to identify the files to be imported.
   with open(CalcFile,'r') as f:
      sCalc = f.read()
      f.close()
   dCalc = ParseFile(sCalc,["calcid","name","record","desc","geomid","basename","aux"])

   # sanity check the parsed details first
   assert( dCalc["CALCID"].isdigit() and dCalc["GEOMID"].isdigit() )
   dCalc["CALCID"] = int(dCalc["CALCID"])
   dCalc["GEOMID"] = int(dCalc["GEOMID"])
   lrec = dCalc["RECORD"].split(".",1)
   # also accept default file name 2
   if len(lrec) == 2:
      assert (lrec[0].isdigit() and lrec[1].isdigit())
      rec,fil = int(lrec[0]),int(lrec[1])
   elif len(lrec) == 1:
      assert (lrec[0].isdigit())
      rec,fil = int(lrec[0]),2
   else:
      raise Exception("Unknown entry in .calc file: " + dCalc["RECORD"])
   dCalc["RECORD"] = str(rec)+"."+str(fil) # reconstruct it again

   # construct full path names of different files using basename
   BaseName = dCalc["BASENAME"]
   filepfx = CalcDir + "/" + BaseName + "."
   (fXYZ,fWfu,fInp,fOut,fRes,fCalc,fPun,fXml) = tuple(filepfx + x for x in ["xyz","wfu","com","out","res","calc","pun","xml"])

   # all files must exist and be readable
   misc.CheckFileAccess(fXYZ,bRead=True,bAssert=True)
   misc.CheckFileAccess(fWfu,bRead=True,bAssert=True)
   misc.CheckFileAccess(fInp,bRead=True,bAssert=True)
   misc.CheckFileAccess(fOut,bRead=True,bAssert=True)
   misc.CheckFileAccess(fRes,bRead=True,bAssert=True)
   misc.CheckFileAccess(fCalc,bRead=True,bAssert=True)
   misc.CheckFileAccess(fPun,bRead=True,bAssert=True)
   misc.CheckFileAccess(fXml,bRead=True,bAssert=True)

   # .calc within Import directory must have same contents as CalcFile
   with open(fCalc,'r') as f:
      sCalcImport = f.read()
      f.close()
      assert (sCalc == sCalcImport)

   # now we are ready to open the data base and add record to Calc table
   try:

      con = sqlite3.connect(Db)
      # use row factory which is far better and has dictionary-like access to data
      con.row_factory = sqlite3.Row
      
      # define cursor
      cur = con.cursor()

      #query db for geometry and calctype
      GeomId = dCalc["GEOMID"]
      CalcId = dCalc["CALCID"]

      cur.execute('SELECT * from Geometry WHERE Id=?',(GeomId,))
      GeomRow  = cur.fetchall()
      assert (len(GeomRow) == 1)
      cur.execute('SELECT * from CalcInfo WHERE Id=?',(CalcId,))
      InfoRow  = cur.fetchall()
      assert (len(InfoRow) == 1)

      GeomRow = GeomRow[0]
      InfoRow = InfoRow[0]

      # construct geometry object for this geometry and produce its xyz file
      gobj = geometry.Geometry(rho=GeomRow["rho"],theta=GeomRow["theta"],phi=GeomRow["phi"],id=GeomRow["id"])
      sXYZ = gobj.to_xyzstr()

      # xyz file also must match
      with open(fXYZ,'r') as f:
         sXYZcalc = f.read()
         f.close()
         assert (sXYZ == sXYZcalc)

      # now xyz and calc files match each other, so geometry is correct
      # names also must match
      assert (dCalc["NAME"] == InfoRow["name"])

      # check if different record is being used
      #if (dCalc["RECORD"] != InfoRow["orbrec"]):
      #   print "different record number from templaet is being used; hope you are advanced user!"

      # check if this calc already exists for this geometry; this is error.
      # to add a calc which already exists, you will need to remove this first.
      cur.execute("SELECT * FROM CALC where GeomId=? AND CalcId=?",(GeomId,CalcId))
      if cur.fetchall():
         raise Exception("The calculation being imported already exists in the Database")
      
      # collect results from the files and add it to data base
      sResults = GetResults(InfoRow["resvars"],fRes)

      # The BaseName supplied in .calc file SHOULD not be used in destination directory
      # even if it matches our final destination base name.
      # we change base name now
      BaseNameDb = InfoRow["Type"] + str(CalcId) + "-" + "geom" + str(GeomId)
      fDbWfu = BaseNameDb + ".wfu"
      fDbInp = BaseNameDb + ".com"
      fDbOut = BaseNameDb + ".out"
      fDbRes = BaseNameDb + ".res"
      fDbPun = BaseNameDb + ".pun"
      fDbXml = BaseNameDb + ".xml"
      fDbXYZ = BaseNameDb + ".xyz"
      # we will not copy calc file, it is not necessary.

      # Define DestDir where the result will go;
      # Create them before database is modified
      DestGeomDir = DestBaseDir + "/" + "geom" + str(GeomId)
      if os.path.exists(DestGeomDir):
         if os.path.isdir(DestGeomDir):
            # check if it is writable
            misc.CheckDirAccess(DestGeomDir,bRead=False,bAssert=True)
         else:
            raise Exception(DestGeomDir + " is not a directory")
      else:
         # create it
         os.mkdir(DestGeomDir,0775)
      
      DestCalcDir = DestGeomDir + "/" + InfoRow["type"] + str(CalcId)
      if os.path.exists(DestCalcDir):
         # this is an error -- can not import if it already exists
         raise Exception(DestCalcDir + " already exists at Destination ")
      else:
         # create it now
         os.mkdir(DestCalcDir,0775)
      
      DestDir = os.path.relpath(DestCalcDir,start=DestBaseDir)
      
      # collect all the information into a tuple for insertion to Calc data base
      # we will now insert Dir field to be relative to DestBaseDir
      tcalc = (GeomId,CalcId,DestDir,fDbWfu,dCalc["RECORD"],fDbInp,\
               fDbOut,fDbRes,dCalc["AUX"],sResults,dCalc["DESC"])
      try:
        cur.execute("""INSERT INTO Calc (GeomId,CalcId,Dir,WfnFile,OrbRec,InputFile,
                       OutputFile,ResultFile,AuxFiles,Results,Desc)
                       VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""", tcalc)

        # Now we copy into DestCalcDir as different files
        # DestCalcDir will have full path name
        # .calc file should not be copied to dest -- its useless
        # if INSERT fails, this code is not executed
        # in the most unlikely case, the directory would not be added to data base
        shutil.copy(fXYZ,DestCalcDir + "/" + fDbXYZ)
        shutil.copy(fWfu,DestCalcDir + "/" + fDbWfu)
        shutil.copy(fInp,DestCalcDir + "/" + fDbInp)
        shutil.copy(fOut,DestCalcDir + "/" + fDbOut)
        shutil.copy(fRes,DestCalcDir + "/" + fDbRes)
        shutil.copy(fPun,DestCalcDir + "/" + fDbPun)
        shutil.copy(fXml,DestCalcDir + "/" + fDbXml)

        # gzip the wfu file
        subprocess.call(["gzip", "-9", DestCalcDir + "/" + fDbWfu])

        # now we are done, release
        con.commit()

      except sqlite3.Error, e:
         print e
         print "This is sqlite3 error, check consistency in data base"
         raise
      except IOError, e:
         print e
         print "IOError occured, possibily a file copying error."
         print "The data base has been modified"
         print "Check if files on dir are in sync with db"
         raise

   except sqlite3.Error, e:
      print e
      print "This is sqlite3 error; nothing has been copied to data base"
      raise

   except:
      print "Some error happened; data base has not been modified"
      raise

def ImportDirList(Args,Db,BaseDir,DirList,DataDir):
   """ This tries to import all calculations found in DirList into DataDir.
       Each directory in DirList is imported if possible.
       For the import to be successful, the .calc file must be present
       in that directory; only one .calc file must be present. """
   # first if each directory in DirList is readable
   DirCalcList = []
   for Dir in DirList:
      DirFull = BaseDir + "/" + Dir
      misc.CheckDirAccess(DirFull,bRead=True,bAssert=True)
      lfall = [ f for f in os.listdir(DirFull) ]
      lf = [ f for f in lfall if f.endswith(".calc") ]
      if len(lf) == 0:
         raise Exception("The directory " + DirFull + " has no .calc file")
      elif len(lf) > 1:
         raise Exception("The directory " + DirFull + " has " + len(lf) + " .calc files")
      else:
         # now there is only one calc file
         CalcFile = lf[0]
         base,extcalc = os.path.splitext(CalcFile)
         # check if all remaining files are physically present
         for ext in [".xyz",".wfu",".com",".out",".res",".pun",".xml"]:
            if not ((base + ext in lfall) and misc.CheckFileAccess(DirFull + "/" + base + ext,bRead=True,bAssert=False)):
               raise Exception("File " + base + ext + " is not found in " + DirFull)
         DirCalcList.append((DirFull,DirFull + "/" + CalcFile))

   # the DataDir should be writeable.
   misc.CheckDirAccess(DataDir,bRead=False,bAssert=True)

   # now we can import
   for (CalcDir,CalcFile) in DirCalcList:
      print "Importing ...",CalcDir,"...",
      ImportCalc(Db,CalcDir,CalcFile,DataDir,Verbose=Args.Verbose)
      print "done"

def ImportNearNbrJobs(Args):
    """ Import a nearest neighbour type of export job.
    
    Db        -- Data base file
    ExportDir -- The directory under which jobs and export.dat file is found.
                 The individual jobs will under this directory.
    DataDir   -- The base directory where imported data will be copied to.
                 For example "GeomData"
    ExportId  -- The export id -> must match one in export.dat file.
                 If it is 0, then it will be read from export.dat file.
    """
    Db = Args.DbMain
    ExportDir = Args.ExportDir
    DataDir = Args.PESDir
    ExportId = Args.ExportId

    # Db must have read as well as write access
    misc.CheckFileAccess(Db,bRead=True,bAssert=True)
    misc.CheckFileAccess(Db,bRead=False,bAssert=True)
   
    # ExportDir should have read access
    # DataDir should have write access
    misc.CheckDirAccess(ExportDir,bRead=True,bAssert=True)
    misc.CheckDirAccess(DataDir,bRead=False,bAssert=True)

    # If ExportId is not available, then it will be picked up from export.dat file
    if ExportId == 0:
       fExpDat = ExportDir + "/" + "export.dat"
       with open(fExpDat,'r') as f:
           sExpDat = f.read()
           f.close()
       dExpDat = ParseFile(sExpDat,['ExpId','CalcDirs'])
       ExportId = int(dExpDat['EXPID'])
   
    # open data base and obtain details of ExportId
    ImportGeomIdsDirsDb = []
    ExportsRow = None
    with sqlite3.connect(Db) as con:
        # use row factory which is far better and has dictionary-like access to data
        con.row_factory = sqlite3.Row
        cur = con.cursor()
        cur.execute('SELECT * FROM Exports WHERE Id=?',(ExportId,))
        exp_row = cur.fetchall()
        if exp_row:
            assert (len(exp_row) == 1)
            ExportsRow = exp_row[0]
        else:
            raise Exception("ExportId = " + str(ExportId) + " not found in data base")
        # first check if this export is "open" -- its an error to import a closed export
        if ExportsRow['Status'] != 0:
            raise Exception("Can not import. Export Id " + str(ExportId) + " is already closed.")

        # now obtain list of jobs which can be imported.
        cur.execute("SELECT GeomId,CalcDir FROM ExpCalc where ExpId=?",(ExportId,))
        expcalc_row = cur.fetchall()
        for row in expcalc_row:
            ImportGeomIdsDirsDb.append((row['GeomId'],row['CalcDir']))
            
    # if there are no calculations to be imported
    if not ImportGeomIdsDirsDb:
        raise Exception("There are no calculations to be imported. Please check Data base.")

    # now we have the list of geometries and directories to be imported - as per Db
    # we read export.dat file and confirm if everything is okay
    fExpDat = ExportDir + "/" + "export.dat"
    with open(fExpDat,'r') as f:
        sExpDat = f.read()
        f.close()
    dExpDat = ParseFile(sExpDat,['ExpId','CalcDirs'])
    # obtain a list of incomplete jobs
    # such jobs will not have corresponding .calc file, but .calc_ file
    CalcDirs = dExpDat['CALCDIRS'].split()
    CalcDirsDone = [d for d in CalcDirs if os.path.isfile(ExportDir + "/" + d + "/" + d + ".calc")]
    if Args.Verbose:
       if CalcDirsDone:
          print len(CalcDirsDone), " jobs can be imported out of total possible jobs ", len(CalcDirs)
       else:
          print "No importable jobs in directory", ExportDir
    
    # now we need to reconcile both these lists.
    # it might be that some calculations are already imported previously
    # it may also happen that all still remaining on db are being imported now.
    # we will now prepare a final list of directories to be imported
    CalcDirsToImport = []
    GeomIdsToImport = []
    for (g,d) in ImportGeomIdsDirsDb:
        if d in CalcDirsDone:
            CalcDirsToImport.append(d)
            GeomIdsToImport.append(g)
    assert (len(CalcDirsToImport) == len(GeomIdsToImport))

    if Args.Verbose:
       if CalcDirsToImport:
          print len(CalcDirsToImport), " jobs will be imported out of total importable jobs ", len(CalcDirsDone)
       else:
          print "No jobs will be imported from ", ExportDir

    # now import
    ImportDirList(Args,Db,ExportDir,CalcDirsToImport,DataDir)
    
    # now remove imported job from ExpCalc table in data base
    # update Exports table with imported list of geometries
    # if all geometries are imported, change the status
    with sqlite3.connect(Db) as con:
        # use row factory which is far better and has dictionary-like access to data
        con.row_factory = sqlite3.Row
        cur = con.cursor()
        for GeomId,CalcDir in zip(GeomIdsToImport,CalcDirsToImport):
            cur.execute('DELETE FROM ExpCalc WHERE ExpId=? AND GeomId=? AND CalcDir=?',(ExportId,GeomId,CalcDir))
        # update exports table using ExportsRow already available
        sImpGeomIds = ExportsRow['ImpGeomIds']
        if sImpGeomIds:
            # already some entry is there, append it
            sImpGeomIds += "," + ",".join([str(g) for g in GeomIdsToImport])
        else:
            # fresh entry
            sImpGeomIds = ",".join([str(g) for g in GeomIdsToImport])
        cur.execute("UPDATE Exports SET ImpDT=datetime('now','localtime'), ImpGeomIds=? WHERE Id=?",(sImpGeomIds,ExportId))
        # commit now
        con.commit()
        # if no geometries remain to be imported, change the status to closed
        cur.execute("SELECT * FROM ExpCalc where ExpId=?",(ExportId,))
        expcalc_row = cur.fetchall()
        if expcalc_row:
            # geometries remain to be imported
            print "Export with Id = " + str(ExportId) + " is not closed."
            pass
        else:
            # all have been imported
            cur.execute("UPDATE Exports SET Status=1 WHERE Id=?",(ExportId,))
            print "Export with Id = " + str(ExportId) + " is been closed."
        # all done with import
        con.commit()

    # done
    print str(len(CalcDirsToImport)) + " Jobs have been successfully imported."

def ExportCalc(Db,GeomId,CalcTypeId,DataDir,ExpDir,ComTemplate="",StartId=0,BaseSuffix="",Verbose=False):
   """ Export a calculation for geometry and produce the files required for calculation.
       This routine is supposed to be a low-level version and does not modify database.
       It uses data base in order to access or copy the data required for export.

     Db           -- The data base file
     GeomId       -- Id of geometry to be exported (in the Geometry table)
     CalcTypeId   -- Id of type of calculation to be exported (in the CalcInfo table)
     DataDir      -- The base directory where data is availble -- must be passed in
     ExpDir       -- The directory in which a sub-directory for this calc is to be created and files are be placed.
     ComTemplate  -- Template file to be used for export; if empty, then default is used.
     StartId      -- If non-zero, it is Id (in Calc table) of another already existing calculation.
                     The wfu file from this calculation copied and its name changed appropriately.
                     The input file generated will have orbital record from the copied wfu file.
                     NOTE : This can be used for to start from
                        * a completed calculation at a neighbouring geometry of this geometry.
                        * another completed calculation at this geometry.
   """
   # first do some sanity checks before we export.
   misc.CheckDirAccess(DataDir,bRead=True,bAssert=True)
   misc.CheckDirAccess(ExpDir,bRead=False,bAssert=True)
   misc.CheckFileAccess(Db,bRead=True,bAssert=True)

   # the given geometry must exist in the Geometry table
   # the calculation must be defined in the CalcInfo table.
   assert (GeomId)
   assert (CalcTypeId)
   with sqlite3.connect(Db) as con:

      # use row factory which is far better and has dictionary-like access to data
      con.row_factory = sqlite3.Row
      cur = con.cursor()

      # GeomId and CalcTypeId check
      cur.execute('SELECT * from Geometry WHERE Id=?',(GeomId,))
      geom_row = cur.fetchall()
      assert (len(geom_row) == 1)
      cur.execute('SELECT * from CalcInfo WHERE Id=?',(CalcTypeId,))
      info_row = cur.fetchall()
      assert (len(info_row) == 1)
      # extract details of this geometry and calculation, we will need them later
      GeomRow = geom_row[0]
      InfoRow = info_row[0]

      # now on, we will make it an error to export something already present in Calc table
      # TODO: change this to allow some flexibility to repeat a calculation.
      cur.execute('SELECT * from Calc WHERE GeomId=? AND CalcId=?',(GeomId,CalcTypeId))
      if cur.fetchall():
         # non-zero records, this calculation already exists.
         raise Exception("Error: The calculation of type CalcTypeId=%r on GeomId=%r already exists" % (CalcTypeId,GeomId))

      # if the calculation is declared to be dependent on another calculation type
      # make sure the that calculation results are available on the data base.
      # otherwise no point in exporting -- is there a point doing mrci which depends on some multi
      CalcTypeIdDep = InfoRow["Depends"]
      if CalcTypeIdDep:
         # check the CalcInfo table for details of this calculation type
         cur.execute("SELECT * from CalcInfo WHERE Id=?",(CalcTypeIdDep,))
         irow = cur.fetchall()
         if len(irow) == 1:
            # now check if there is calculation of this type on this geometry in Calc table
            cur.execute("SELECT * from Calc WHERE GeomId=? AND CalcId=?",(GeomId,CalcTypeIdDep))
            crow = cur.fetchall()
            if len(crow) == 0:
               # the calculation is not available, raise exeception
               raise Exception("This calculation depends on CalcId=%r which does not exist in Calc table" % (CalcTypeIdDep,))
            else:
               # there must be exactly one such calculation -- just to make sure
               assert(len(crow) == 1)
         else:
            # invalid CalcTypeIdDep provided -- this is error in config file supplied
            raise Exception("Invalid CalcId for Depends field -- check config file for this calc type")
      # now dependency conditions are met.

      # now prepare for generating the calc file
      CalcName = InfoRow["Name"]
      if ComTemplate:
         InpTempl = ComTemplate
      else:
         InpTempl = InfoRow["InpTempl"]
      Record = InfoRow["OrbRec"]
      Desc = "" # Desc in CalcInfo is not relevant
      Aux = ""

      # if StartId is non-zero, then it must exist in Calc table.
      # we gather details necessary for setting up such input
      # we need:
      #    wfn file of calculation
      #    the record number of orbitals
      bUnzip = False
      if StartId:
         cur.execute('SELECT * from Calc WHERE Id=?',(StartId,))
         start_row = cur.fetchall()
         assert (len(start_row) == 1)
         StartCalcRow = start_row[0]
         # pickup details from here -- needed for completing template file
         StartDir = DataDir + "/" + StartCalcRow["Dir"]
         StartWfnFile = StartCalcRow["WfnFile"]
         StartRecord = StartCalcRow["OrbRec"]
         # check access for wave-function -- it could be a zip file
         misc.CheckDirAccess(StartDir,bRead=True,bAssert=True)
         if misc.CheckFileAccess(StartDir + "/" + StartWfnFile,bRead=True,bAssert=False):
            bUnzip = False
         elif misc.CheckFileAccess(StartDir + "/" + StartWfnFile + ".gz",bRead=True,bAssert=False):
            bUnzip = True
         else:
            raise Exception("Wavefunction file=%r does not exist" %(StartWfnFile,))


      # decide basename needed for generated files
      # we can use a combination of geometry and calculation name to be sure
      # basename = CalcType + CalcId + "-" + "geom" + GeomId
      # this works out something like "multi2-geom1" .. should be fine I think.
      # TODO: do this optimally if these turn out to be too difficult to navigate.
      BaseName = InfoRow["Type"] + str(CalcTypeId) + "-" + "geom" + str(GeomId)
      if BaseSuffix:
         BaseName = BaseName + "-" + BaseSuffix

      # create required directory
      ExportDir = ExpDir + "/" + BaseName
      os.mkdir(ExportDir,0775)

      # now we are ready to generate files, first calc and xyz files
      sCalcFile = GenCalcFile(CalcTypeId,GeomId,CalcName,Record,BaseName,Desc="",Aux="")
      GeomObj = geometry.Geometry(GeomRow["rho"],GeomRow["theta"],GeomRow["phi"],id=GeomId)
      sXYZFile = GeomObj.to_xyzstr()

      # write them out
      # for calc file, we will generate it as .calc_ <--- note extra underscore at end
      # this is to safegaurd against faulty imports.
      # this should be renamed to .calc upon successful run
      fCalc = ExportDir + "/" + BaseName + ".calc_"  # <-- extra underscore
      fXYZ  = ExportDir + "/" + BaseName + ".xyz"
      with open(fCalc,'w') as f:
         f.write(sCalcFile)
         f.close()
      with open(fXYZ,'w') as f:
         f.write(sXYZFile)
         f.close()

      # if wfn file needs to be copied from elsewhere, do that now
      if StartId:
         fSrcWfn = StartDir + "/" + StartWfnFile # this has .wfu extension already
         fDstWfn = ExportDir + "/" + BaseName + ".wfu"
         if bUnzip:
            fSrcWfn += ".gz"
            fDstWfn += ".gz"
         shutil.copy(fSrcWfn,fDstWfn)
         if bUnzip:
            subprocess.call(["gzip", "-d", fDstWfn])
            
      # now input file -- apply replacement substitutions to template string
      s0 = InpTempl.replace("$F$",BaseName)
      s1 = s0.replace("$R$",Record)
      # $S$ may not exist in all files
      if s1.count("$S$"):
         # substitute with starting record if asked for
         if StartId:
            sInpFile = s1.replace("$S$",StartRecord)
         else:
            sInpFile = s1
            print "WARNING: template not fully substituted -- check input file"
      else:
         sInpFile = s1
      # generate input file
      fInp = ExportDir + "/" + BaseName + ".com" # we have decided to generate .com and not .inp
      with open(fInp,'w') as f:
         f.write(sInpFile)
         f.close()

      # done with exporting
      # we will return base name to the calling routine
      if Verbose:
         print "\tJob for GeomId=",GeomId," exported to", ExportDir
      return BaseName

def ExportGeometries(Args,ExportList,ExpDir):
   """ this exports a list of geometries to separate directories """

   # ExpDir should have write access, and PES Data Dir must have read access
   misc.CheckDirAccess(ExpDir,bRead=False,bAssert=True)
   misc.CheckDirAccess(Args.PESDir,bRead=True,bAssert=True)

   ExportedDirs = []
   for (GeomId,StartCalcId,BaseSuffix) in ExportList:
      BaseName = ExportCalc(Args.DbMain,GeomId,Args.CalcTypeId,Args.PESDir,ExpDir,
                            ComTemplate=Args.ComTemplate,StartId=StartCalcId,
                            BaseSuffix=BaseSuffix,Verbose=Args.Verbose)
      # collect list of base names exported
      ExportedDirs.append(BaseName)

   # done, return list of exported directories for later processing
   if Args.Verbose:
      print
      print "\tA total of ",len(ExportedDirs)," geometries has been exported to jobs in ",ExpDir
   return ExportedDirs

sRunJobPythonFilePrefix = r'''#!/usr/bin/python
# -*- coding: utf-8 -*-

import os
import os.path
import shutil
import subprocess
import time

""" A context manager to run molpro jobs in some directory """
from contextlib import contextmanager

@contextmanager
def cd(newdir):
    prevdir = os.getcwd()
    os.chdir(os.path.expanduser(newdir))
    try:
        yield
    finally:
        os.chdir(prevdir)

def RunMolpro(RunDir,ScrDir,ComFile,bDryRun=False):
   """ This runs molpro file 'ComFile' located in RunDir. """
   with cd(RunDir):
      if bDryRun:
         # create all files that molpro would do
         base,ext = os.path.splitext(ComFile)
         subprocess.call(["touch",base+".wfu"])
         subprocess.call(["touch",base+".out"])
         subprocess.call(["touch",base+".res"])
         subprocess.call(["touch",base+".pun"])
         subprocess.call(["touch",base+".xml"])
         exitcode = 0
      else:
         exitcode = subprocess.call(["molpro", "-d", ScrDir, "-W .", ComFile])
      return exitcode

def ParseFile(sfile,lkeys):
   """ A generic parser which can parse key : value pairs from any string and return a dictionary of parsed options """
   def remove_comments(s):
       p = s.find("#")
       if p >=0:
          snew = s[0:p]
       else:
          snew = s
       return snew.strip()
   ls0 = [x.strip() for x in sfile.splitlines() if x.strip()]
   ls1 = [tuple(x.split(":")) for x in ls0 if remove_comments(x)]
   for t in ls1:
      assert (len(t) == 2)
   ls2 = [(x.strip(),y.strip()) for (x,y) in ls1]
   lparse = { k.upper():v for (k,v) in ls2 }
   for key in lkeys:
      assert( key.upper() in lparse )
   assert (len(lparse) == len(lkeys))
   return lparse

def RunExportedCalcs(MolproScrDir):
   """ Run or continue a series of exported jobs."""

   fExpDat = "export.dat";
   fRunLog = "run.log";

   # first open export.dat file and collect information about exported jobs
   with open(fExpDat,'r') as f:
      sExpDat = f.read()
      f.close()
   dExpDat = ParseFile(sExpDat,['ExpId','CalcDirs'])

   # obtain a list of incomplete jobs
   # such jobs will not have corresponding .calc file, but .calc_ file
   CalcDirs = dExpDat['CALCDIRS'].split()
   DirsDone = [d for d in CalcDirs if os.path.isfile(d+"/"+d+".calc")]
   DirsToDo = [d for d in CalcDirs if os.path.isfile(d+"/"+d+".calc_")]
   if len(CalcDirs) != len(DirsDone) + len(DirsToDo):
      raise Exception("Some dirs in this export directory = " + os.getcwd() + " seem to not have .calc/.calc_ file.")

   # Before we run, indicate run details into Log file.
   # open log file in append mode
   fLog = open(fRunLog,"a")
   fLog.write(100*"*"+"\n")
   fLog.write(30*" " + time.asctime(time.localtime())+"\n")
   fLog.write(100*"*"+"\n")
   fLog.write("\n")
   for d in DirsDone:
      fLog.write("Skipping already compelted job Dir " + d + "\n")
   fLog.flush()
   os.fsync(fLog)

   # now execute each job
   for RunDir in DirsToDo:

      # job will be now done
      fLog.write("Begin Job " + RunDir + " on " + time.asctime(time.localtime()) + "\n")
      fLog.flush()
      os.fsync(fLog)

      ScrDirCalc = os.path.expanduser(MolproScrDir + "/" + "scr-" + RunDir)
      os.mkdir(ScrDirCalc,0775)
      fComBaseFile = RunDir + ".com"

      exitcode = RunMolpro(RunDir,ScrDirCalc,fComBaseFile,bDryRun=False)

      if exitcode == 0:

         # molpro has run successfully, update log
         fLog.write("   Completed on " + time.asctime(time.localtime()) + "\n")
         fLog.write("\n")
         fLog.flush()
         os.fsync(fLog)

         # rename .calc_ file so that it can be imported
         os.rename(RunDir + "/" + RunDir + ".calc_", RunDir + "/" + RunDir + ".calc")

      else:

         # molpro has not run successfully, indicate it
         fLog.write("   JOB UNSUCCESSFUL ON " + time.asctime(time.localtime()) + "\n")
         fLog.write("\n")
         fLog.flush()
         os.fsync(fLog)

      # remove scratch directory
      subprocess.call(["rm","-rf",ScrDirCalc])

   # finish and close log file     
   fLog.write("Run of Exported Calcs Completed on " + time.asctime(time.localtime()))
   fLog.write("\n")
   fLog.write(100*"*"+"\n")
   fLog.write("\n")
   fLog.write("\n")
   fLog.flush()
   os.fsync(fLog)
   fLog.close()
   
if __name__ == '__main__':

   # define molpro scratch, this will be properly expanded during runtime
   MolproScrDir = "~/MOLPRO_SCRATCH"
   
   # now run jobs
   RunExportedCalcs(MolproScrDir)

'''

def GetExpGeomNearNbr(Db,CalcTypeId,MaxGeom=50,NbrDepth=1,NbrDb="",bIncludePath=False,Verbose=False):
   """ Returns a list of nearest neighbour geometries which can be exported.
       A list of (GeomId,CalcId) is returned where
          GeomId : geometry to be exported
          CalcId : the id in calc table which corresponds to nearnest neighbour of GeomId.
       This will return an empty list if it can not export.
       
       Algorithm:
       **********
       This tries to return, as far as possible, 'MaxGeom' geometries.
       Parameter NbrDepth controls how neighbour geometries are selected.
       
       If NbrDepth is 1/2/3, then NNId,NNId1,NNId2 fields of Db are used.
       Depth is increased upto (and not including) NbrDepth and for each
       value of Depth, the corresponding NNId field is used. As soon as
       target of MaxGeom is acheived, the search is stopped.
       
       If NbrDepth > 3, then NbrDb data base is used along with Db.
       Depth is increased from 3 upto NbrDepth-1 and for each value of Depth,
       all geometries at this depth are fetched from NbrTable table in NbrDb.
       Next Depth is attempted if target is not met.
       
       If NbrDepth <= 0, then a different algorithm is used. The NbrDb is opened
       and all geometries in NbrTable are tried in the increasing order of Dist field.
       The results should be qualitatively similar to earlier case.
       
       The flag bIncludePath forces pathological points to be included.
       It is imagined that this latter flag is used conservatively, starting with
       NbrDepth=1 and going up to 3.
       
       TODO: There is too much repeated code in here; needs to be shortened.
       
   """

   misc.CheckFileAccess(Db,bRead=True,bAssert=True)
   with sqlite3.connect(Db) as con:

      con.row_factory=sqlite3.Row
      cur = con.cursor()

      # first collect list of geometries for which calculations have been done
      cur.execute("SELECT Id,GeomId FROM Calc WHERE CalcId=?",(CalcTypeId,))
      lrow = cur.fetchall()
      if len(lrow) < MaxGeom:
         raise Exception("Not enough number of completed calculations present in database")

      # create a list of geometry ids of completed calculations
      # create a dictionary mapping geometry id to calcid -- to be used later
      CalcGeomIds = []
      DictCalcId = {}
      for row in lrow:
         CalcGeomIds.append(row["GeomId"])
         DictCalcId[row["GeomId"]] = row["Id"]

      # sort CalcGeomIds list so that binary search can be done on it
      # this is important; linear search becomes pretty slow.
      CalcGeomIds.sort()

      # look into exports table and build a list of geometries which must be
      # excluded because they are already computed or already exported.
      # ExpCalc table keeps a list of geometries already exported.
      ExcludeGeomIds = []
      ExcludeGeomIds.extend(CalcGeomIds)
      cur.execute("SELECT * FROM Exports WHERE CalcType=?",(CalcTypeId,))
      lrow = cur.fetchall()
      for row in lrow:
         cur.execute("SELECT GeomId FROM ExpCalc WHERE ExpId=?",(row['Id'],))
         lgeom = cur.fetchall()
         for lg in lgeom:
            ExcludeGeomIds.append(lg['GeomId'])

      # pathological cases can also be excluded if asked for.
      # TODO : I am not sure this option works -- needs to test it
      #if not bIncludePath:
      #    cur.execute("SELECT Id FROM Geometry WHERE tags LIKE '%path%'")

      # sort this list so that binary search can be done on it
      ExcludeGeomIds.sort()

      # initialize the the list of geometries which can be exported
      # the corresponding list contains calcid of neighbour geometries
      ExpGeomIdList = []
      ExpCalcIdList = []

      # for each depth up to 3, we search within Geometry table
      for Depth in range(min(NbrDepth,3)):
          
          # for current 'Depth', decide the NNId field in Geometry table
          NNIdField = "NNId"
          if Depth > 0:
              NNIdField += str(Depth)
              
          # go through all geometries in the table
          cur.execute("SELECT Id,{0} FROM Geometry".format(NNIdField))
          for GeomRow in cur:
              
              # check if target is achieved
              if len(ExpGeomIdList) == MaxGeom:
                  break
              
              GeomId = GeomRow["Id"]
              NbrId = GeomRow[NNIdField]

              # skip if this geometry is in exclude list
              # this list is potentially large - hence binary search
              i = bisect.bisect_left(ExcludeGeomIds,GeomId)
              if i != len(ExcludeGeomIds) and ExcludeGeomIds[i] == GeomId:
                  continue
              
              # skip if geometry is already included - it is a small list
              if GeomId in ExpGeomIdList:
                  continue
              
              # find if its neighbouring geometry at this depth is done
              # binary search should get over in max log(58000,base=2) approx 16 iterations
              i = bisect.bisect_left(CalcGeomIds, NbrId)
              if i != len(CalcGeomIds) and CalcGeomIds[i] == NbrId:
                  # the neighbouring geometry is in the list of done calcs.
                  # push it to export list
                  ExpGeomIdList.append(GeomId)
                  ExpCalcIdList.append(DictCalcId[NbrId])
                  
          # check if target is achieved
          if len(ExpGeomIdList) == MaxGeom:
              break
        
      # if target is met, return
      if len(ExpGeomIdList) == MaxGeom:
          return zip(ExpGeomIdList,ExpCalcIdList)
          
      # reaching here means that target is still not met
      # now we will use NbrTable in NbrDb to expand the search
      # TODO : the following loop can be merged with previous one.
      misc.CheckFileAccess(NbrDb,bRead=True,bAssert=True)
      with sqlite3.connect(NbrDb) as conNbr:
          
          conNbr.row_factory=sqlite3.Row
          curNbr = conNbr.cursor()
          
          for Depth in range(3,NbrDepth):
              
              # for current 'Depth', obtain list of geometries and neighbours
              curNbr.execute("SELECT GeomId,NbrId FROM NbrTable WHERE Depth=?",(Depth,))
              
              # now go through all such geometries and see if they can be exported
              for NbrRow in curNbr:
                  
                  # check if target is achieved
                  if len(ExpGeomIdList) == MaxGeom:
                      break
                  
                  GeomId = NbrRow["GeomId"]
                  NbrId = NbrRow['NbrId']
    
                  # skip if this geometry is in exclude list
                  # this list is potentially large - hence binary search
                  i = bisect.bisect_left(ExcludeGeomIds,GeomId)
                  if i != len(ExcludeGeomIds) and ExcludeGeomIds[i] == GeomId:
                      continue
                  
                  # skip if geometry is already included - it is a small list
                  if GeomId in ExpGeomIdList:
                      continue
                  
                  # find if its neighbouring geometry at this depth is done
                  # binary search should get over in max log(58000,base=2) approx 16 iterations
                  i = bisect.bisect_left(CalcGeomIds, NbrId)
                  if i != len(CalcGeomIds) and CalcGeomIds[i] == NbrId:
                      # the neighbouring geometry is in the list of done calcs.
                      # push it to export list
                      ExpGeomIdList.append(GeomId)
                      ExpCalcIdList.append(DictCalcId[NbrId])
                      
              # check if target is achieved
              if len(ExpGeomIdList) == MaxGeom:
                  break

      # if target is now met, return
      if len(ExpGeomIdList) == MaxGeom:
          return zip(ExpGeomIdList,ExpCalcIdList)

      # reaching here means that target is still not met
      # now we will try alternative algorithm
      # this may not work any better than previous one
      # this part can also be directly reached by setting NbrDepth <= 0

      # now we will use NbrTable in NbrDb to expand the search
      # but in a different way based purely on Dist field
      misc.CheckFileAccess(NbrDb,bRead=True,bAssert=True)
      with sqlite3.connect(NbrDb) as conNbr:
          
          conNbr.row_factory=sqlite3.Row
          curNbr = conNbr.cursor()
          
          # obtain list of geometries based on ascending order of Dist field
          curNbr.execute("SELECT GeomId,NbrId FROM NbrTable ORDER BY Dist ASC")
              
          # now go through all such geometries and see if they can be exported
          for NbrRow in curNbr:
              
              # check if target is achieved
              if len(ExpGeomIdList) == MaxGeom:
                  break
              
              GeomId = NbrRow["GeomId"]
              NbrId = NbrRow['NbrId']

              # skip if this geometry is in exclude list
              # this list is potentially large - hence binary search
              i = bisect.bisect_left(ExcludeGeomIds,GeomId)
              if i != len(ExcludeGeomIds) and ExcludeGeomIds[i] == GeomId:
                  continue
              
              # skip if geometry is already included - it is a small list
              if GeomId in ExpGeomIdList:
                  continue
              
              # find if its neighbouring geometry at this depth is done
              # binary search should get over in max log(58000,base=2) approx 16 iterations
              i = bisect.bisect_left(CalcGeomIds, NbrId)
              if i != len(CalcGeomIds) and CalcGeomIds[i] == NbrId:
                  # the neighbouring geometry is in the list of done calcs.
                  # push it to export list
                  ExpGeomIdList.append(GeomId)
                  ExpCalcIdList.append(DictCalcId[NbrId])
                  
      # it does not matter if target is met or not, just return
      return zip(ExpGeomIdList,ExpCalcIdList)

def ExportNearNbrJobs(Args):
   """ Export a number of Jobs. This one is the general export.
       Algorithm is described in GetExpGeomNearNbr function.
       Parameters are also described there.
   """

   # ExportDir should have write access
   misc.CheckDirAccess(Args.ExportDir,bRead=False,bAssert=True)

   # first obtain a list of geometries to be exported
   assert (Args.CalcTypeId)
   ExpGeomList = GetExpGeomNearNbr(Args.DbMain,Args.CalcTypeId,
            MaxGeom=Args.NumJobs,NbrDepth=Args.Depth,NbrDb=Args.DbNbr,
            bIncludePath=Args.IncludePath,Verbose=Args.Verbose)
 
   # we will make sure all the data for export is available before initiating the export
   misc.CheckDirAccess(Args.PESDir,bRead=True,bAssert=True)
   with sqlite3.connect(Args.DbMain) as con:
      
      con.row_factory=sqlite3.Row
      cur = con.cursor()
      
      # first find info about this calculation type
      cur.execute('SELECT * from CalcInfo WHERE Id=?',(Args.CalcTypeId,))
      info_row = cur.fetchall()
      assert (len(info_row) == 1)
      InfoRow = info_row[0]
      # extract details about all calculations referred in list of exported geometries
      cur.execute("SELECT * FROM Calc WHERE Id in (" + ",".join([str(y) for x,y in ExpGeomList]) + ")")
      # this hack isnt recommended in sqlite3  -----> ^^^^^^^^^^^^
      lrow = cur.fetchall()
      for row in lrow:
         Dir = Args.PESDir+"/"+row['dir']
         misc.CheckDirAccess(Dir,bRead=True,bAssert=True)
         # wave-function file -- it may be in gzip form
         if misc.CheckFileAccess(Dir+"/"+row['WfnFile'],bRead=True,bAssert=False):
            # file is there in uncompressed form
            pass
         elif misc.CheckFileAccess(Dir+"/"+row['WfnFile']+".gz",bRead=True,bAssert=False):
            # file is in compressed form
            pass
         else:
            # file is not there
            raise Exception("WfnFile = " + row['WfnFile'] + " is not available for export.")
         # the orbital record must be meaningful
         assert(row['OrbRec'])

      # now we export -- things perhaps wont fail now
      # first insert a new row into Exports Table and get its id
      cur.execute("INSERT INTO Exports (Type,CalcType) VALUES (?,?)", (0,Args.CalcTypeId))
      ExportId = cur.lastrowid

      # create a subdir under ExpDir where the current export data goes
      ExpDir = Args.ExportDir + "/" + "Export" + str(ExportId) + "-" + InfoRow['type'] + str(Args.CalcTypeId)
      os.mkdir(ExpDir,0775)

      # prepare a list of geometries to be exported with suffix
      ExpGeomListSuffix = []
      nexp = len(ExpGeomList)
      for i in range(len(ExpGeomList)):
         if nexp < 10:
            s = "{0:01d}".format(i)
         elif nexp < 100:
            s = "{0:02d}".format(i)
         elif nexp < 1000:
            s = "{0:03d}".format(i)
         else:
            s = str(i)
         ExpGeomListSuffix.append(ExpGeomList[i]+(s,)) # <- tuple addition here

      # now export all geometries, this will create all subdirectories
      ExportedDirList = ExportGeometries(Args,ExpGeomListSuffix,ExpDir)

      # if this is successful, then we need to update the Exports table
      cur.execute("UPDATE Exports SET Type=0, NumCalc=?, ExpDir=?, ExpDT=datetime('now','localtime') WHERE Id=?",\
                   (len(ExportedDirList),os.path.abspath(ExpDir),ExportId))

      # we will also need to enter exported geometries in ExpCalc table
      assert(len(ExportedDirList) == len(ExpGeomListSuffix))
      lexpcalc = []
      for i in range(len(ExportedDirList)):
         lexpcalc.append((ExportId,ExpGeomListSuffix[i][0],ExportedDirList[i]))

      cur.executemany("INSERT INTO ExpCalc (ExpId,GeomId,CalcDir) VALUES (?,?,?)",lexpcalc)

      # commit the changes      
      con.commit()

      # now, we are almost done!
      # we need to generate remaining files
      fExportDat = ExpDir + "/" + "export.dat"
      with open(fExportDat,'w') as f:
         f.write("# Auto generated file. Please do not modify\n")
         f.write("ExpId : " + str(ExportId))
         f.write("\n")
         f.write("CalcDirs : " + " ".join(ExportedDirList))
         f.write("\n")
         f.close()
      # change mode of this file to read-only to prevent accidental writes
      os.chmod(fExportDat,0444)

      if Args.Verbose:
         print "Export with ExportId =", ExportId, " has been entered into data base ", Args.DbMain

      # the python file needs to be generated
      fPythonFile = ExpDir + "/" + "RunJob" + str(ExportId) + ".py"
      with open(fPythonFile,'w') as f:
         f.write(sRunJobPythonFilePrefix)
         f.write("\n")
         f.close()

      if Args.Verbose:
         print "Use Python file ", fPythonFile, "to run the generated jobs."

      # chmod to executable
      os.chmod(fPythonFile,0766)

def LinearGeometries(Db,CalcTypeId,ExpDir,bPath=False):
   
   misc.CheckFileAccess(Db,bRead=True,bAssert=True)
   with sqlite3.connect(Db) as con:
      con.row_factory = sqlite3.Row
      cur = con.cursor()
      cur.execute("SELECT Id,Tags from Geometry")
      lrow = cur.fetchall()
      GeomIdList = []
      for GeomRow in lrow:
         tags = GeomRow["Tags"]
         lt = tags.split(":")
         if bPath:
            if "linear" in lt:
               GeomIdList.append((GeomRow["Id"],0))
         else:
            if ("linear" in lt) and ("path" not in lt):
               GeomIdList.append((GeomRow["Id"],0))
      ExportGeometries(Db,CalcTypeId,GeomIdList,ExpDir)
      # we sort GeomIdList appropriately
      #cur.executemany("SELECT Id,Rho,Theta,Phi where Id=?",GeomIdList)
      #lrow = cur.fetchall()
      #lgeom = []
      #for row in lrow:
      #    lgeom.append(geometry.Geometry(row["rho"],row["theta"],row["phi"],id=row["id"]))
      # all geometry objects are available


if __name__ == "__main__":

    pass
#    ExportNearNbrJobs("fh2db-nbr3.db",1,"GeomData","ExpDir",MaxJobs=10,NbrDepth=1)
#==============================================================================
#    import math
#    import geometry
#    import gengrid
#==============================================================================

   #pi = math.pi

#   dbfile = "fh2db.db"

   # if dbfile does not exist, then create it and add tables into it
   #if not os.path.exists(dbfile):
   #   create_tables(dbfile,sql_table_commands)

   # open the data base
   #con = sqlite3.connect(dbfile)
   #cur = con.cursor()

   # now add some data into tables
   # first add a bunch of geometry data
   #lrho = [1.0, 3.0, 5.0] + [6.5 + i for i in range(5)] +[12.0 + 2*i for i in range(6)]
   #lthe = [0.0 + 2.0*i*pi/180.0 for i in range(46) ]
   #lphi = [0.0 + 2.0*i*pi/180.0 for i in range(91) ]

   #lgeom = gengrid.GenerateHSGrid(lrho,lthe,lphi)
   #lghsc = []
   #for g in lgeom:
   #   (r,t,p) = g.to_hsc()
   #   lghsc.append((r,t,p,""))

   # now insert this into data base
   #cur.executemany("""INSERT INTO Geometry (Rho,Theta,Phi,Tags) VALUES (?, ?, ?, ?)""", lghsc)

   # done successfully, now we test other things
   # this should be saved by now
   #lgeom = []
   #for row in cur.execute('SELECT Rho, Theta, Phi, Id FROM Geometry'):
   #   lgeom.append(geometry.Geometry(row[0],row[1],row[2],id=row[3]))

   # add linear and pathlogical tags
   #cur.executemany("""UPDATE Geometry SET Tags=? WHERE Id=?""",[(gengrid.geom_tags(g),g.id) for g in lgeom])

   #f = open("geomdata.txt",'w')
   #for row in cur.execute('SELECT * from Geometry'):
   #   f.write(str(row))
   #   f.write("\n")
   #for g in lgeom:
   #   f.write(str(g))
   #   f.write("\n")
   #f.close()

   # print the geometries currently listed in data base
   #con.commit()
   #con.close()

#==============================================================================
#    DbFile = "fh2db.db"
#    DataDir = "GeomData"
# 
#    ImportDir = "JacobiPathSeed12536"
#    DirList = [ ImportDir+"/"+d for d in os.listdir(ImportDir) if os.path.isdir(ImportDir+"/"+d) ]
# 
#    ImportDirList(DbFile,DirList,DataDir)
#==============================================================================

   

  
   
