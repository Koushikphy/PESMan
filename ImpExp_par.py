import re
import os
import shutil
import tarfile
import sqlite3
from glob import glob
from geometry import geomObj
from multiprocessing import Pool


# initiate the geometry object inside the geometry file and call the methods from there

def parseResult(file):
    # Collects any valid number and returns the result as a string
    with open(file, 'r') as f: txt = f.read()
    txt = txt.replace('D','E')
    res = re.findall(r"(?:(?<=^)|(?<=\s))([+-]?\d+(?:\.\d*)?(?:[eE][+-]?\d+)?)(?=\s|$|\n|\r\n)", txt)
    return ' '.join(res)


def genCalcFile(CalcId,GeomId,CalcName,Basename,sid,fileName,Desc=""):
    # Creates the calc files
    txt = """# This file is automatically generated. Do not edit.
    CalcId   : {}
    GeomId   : {}
    Name     : {}
    Basename : {}
    StartGId : {}
    Desc     : {}""".format(CalcId,GeomId,CalcName,Basename,sid,Desc)
    with open(fileName, "w") as f:
        f.write(txt)


def helper_export(arg):
    return ExportCalc(*arg)

pool = Pool(processes=4)


def ExportNearNbrJobs(dB, calcId, jobs, exportDir, pesDir, templ, gidList, sidList, depth, constDb, includePath, molInfo,logger):
    # Main export function that exports a given number of jobs for a specified calcid type
    # following collects the geomid that are exportable and the calc table id which will be used as their start info
    if calcId > 1: # Mrci or nact export
        ExpGeomList = GetExpMrciNactJobs(dB,calcId, jobs, constDb)
    else:
        ExpGeomList = GetExpGeomNearNbr(dB,calcId, gidList, sidList, jobs, depth, constDb, includePath)

    with sqlite3.connect(dB) as con:
        con.row_factory=sqlite3.Row
        cur = con.cursor()
        cur.execute('SELECT * from CalcInfo WHERE Id=?',(calcId,))
        InfoRow = cur.fetchone()
        assert InfoRow, "No Info for CalcId={} found in data base".format(calcId)
        # insert into database one row and use the id as export id
        cur.execute("INSERT INTO Exports (CalcId) VALUES (?)", (calcId,))
        exportId = cur.lastrowid

        expDir = "{}/Export{}-{}{}".format(exportDir, exportId, InfoRow["type"], calcId)
        # remove the export directory if already exists, may have created from some failed export.
        if os.path.exists(expDir):  shutil.rmtree(expDir) #<<<--- shouldn't have happened
        os.makedirs(expDir)

        expDirs = []
        temp = []
        for ind, (GeomId,StartCalcId) in enumerate(ExpGeomList, start=1):
            temp.append([dB, GeomId, calcId,pesDir,expDir, templ, StartCalcId, str(ind)])

        expDirs = pool.map(helper_export, temp)

        # update the export table and expcalc tables with the exported jobs
        expGeomIds = [i for i,_ in ExpGeomList]
        cur.execute("UPDATE Exports SET NumCalc=?, ExpDT=strftime('%H:%M:%S %d-%m-%Y', datetime('now', 'localtime')), ExpGeomIds=? WHERE Id=?", (len(expDirs), ' '.join(map(str,expGeomIds)), exportId))

        lExpCalc = [(exportId,calcId, i,j) for i,j in zip(expGeomIds, expDirs)]
        cur.executemany("INSERT INTO ExpCalc (ExpId,CalcId,GeomId,CalcDir) VALUES (?,?,?,?)",lExpCalc)

        fExportDat = expDir + "/export.dat"                       # save the export id and exported directories in export.dat file
        with open(fExportDat,'w') as f:
            f.write("# Auto generated file. Please do not modify\n"+ ' '.join(map(str,[exportId]+expDirs)))

        os.chmod(fExportDat,0444)                                  # change mode of this file to read-only to prevent accidental writes

        fPythonFile =   "{}/RunJob{}.py".format(expDir, exportId)  # save the python file that will run the jobs
        createRunJob(molInfo, fPythonFile)
        logger.info("PESMan export successful: Id {} with {} job(s) exported\n".format(exportId, len(ExpGeomList)))
        return expDir, exportId, expDirs



def GetExpGeomNearNbr(dB, calcId, gidList, sidList, jobs, maxDepth, constDb, inclPath):
    # Get the exportable geometries and their start id for mulit jobs, returns
    with sqlite3.connect(dB) as con:
        cur = con.cursor()

        # get jobs that is already done and add to excludegeomlist
        cur.execute("SELECT GeomId,Id FROM Calc WHERE CalcId=?",(calcId,))
        DictCalcId  = dict(cur.fetchall())
        CalcGeomIds = set(DictCalcId.iterkeys())
        ExcludeGeomIds = CalcGeomIds.copy()

        cur.execute("SELECT GeomId FROM ExpCalc WHERE CalcId=?",(calcId,))
        ExcludeGeomIds.update((i for (i,) in cur))
        # ExcludeGeomIds.update(lPrblmGeomIds)

        if gidList:
            sidList += [-1]*(len(gidList)-len(sidList)) # fill sidList if some missing
            DictStartId = dict(zip(gidList, sidList))   # create a dict of start ids

        cond = []
        if gidList:      cond.append( 'id in (' + ",".join(map(str, gidList)) + ')')     #include gidlist
        if constDb:      cond.append( '(' + constDb + ')')                               #include constraint
        if not inclPath: cond.append( "( tags NOT LIKE '%path%' or tags is null)")       #exclude pathological
        # `tags is null` is added as `not like '%path%'` doesn't match `null`!!! Is this the correct way?
        cond = ' where ' + ' and '.join(cond) if cond else ''
        cur.execute('SELECT Id,Nbr FROM Geometry' + cond)


        expGClist = []                                            # list that collects the tuple exportable jobs info
        fullGeomList = []                                         # a naive approach: store all the missed geometries
        for geomId, nbrList in cur:
            if geomId in ExcludeGeomIds: continue                 # geometry already exist, skip
            if gidList and DictStartId[geomId]>=0:                # negetive start id will go to main neighbour searching
                nbrId = DictStartId[geomId]                       # i.e. 0 or positive startid given
                if not nbrId :                                    # 0 startid nothing to do here
                    expGClist.append((geomId, 0))
                elif nbrId in CalcGeomIds :                       # positive start id, include if calculation is already done
                    expGClist.append((geomId, DictCalcId[nbrId]))
                if len(expGClist)==jobs:
                    return expGClist                              # got all the geometries needed
                continue

            nbrList = map(int, nbrList.split())                   # Care ful about integer mapping
            nbrId = nbrList[0]                                    # for this initial loop only consider first neighbour

            if nbrId in CalcGeomIds:
                expGClist.append((geomId, DictCalcId[nbrId]))     # got one match
                if len(expGClist)==jobs:
                    return expGClist
                continue
            fullGeomList.append((geomId, nbrList))

        #Get allowed depth. Provided every nbr list has same number of elements. This is be quite bad, do something better
        depth = maxDepth if maxDepth else len(fullGeomList[0][1]) if fullGeomList else 0
        exportedGeom = set([])
        for d in range(1,depth):                                   # depth loop starting from 1 to end,
            for geomId, nbrList in fullGeomList:
                if geomId in exportedGeom: continue

                nbrId = nbrList[d]                                 # get d-th neighbour
                if nbrId in CalcGeomIds:
                    expGClist.append((geomId, DictCalcId[nbrId]))  # got one match now don't search for any other neighbours
                    if len(expGClist)==jobs:
                        return expGClist
                    exportedGeom.add(geomId)

    assert expGClist, "No Exportable geometries found"         # preventing null exports
    return expGClist


def GetExpMrciNactJobs(dB, calcId, jobs, constDb):

    with sqlite3.connect(dB) as con:
        cur = con.cursor()

        cur.execute("SELECT GeomId FROM Calc WHERE CalcId=? union SELECT GeomId FROM ExpCalc WHERE CalcId=?",(calcId,calcId))
        ExcludeGeomIds = {i for (i,) in cur}  # all exported jobs

        constQuery = ' and GeomId in (SELECT Id FROM Geometry where '+ constDb +' )' if constDb else ''
        cur.execute("SELECT Id,GeomId FROM Calc WHERE CalcId = 1" + constQuery)

        expGClist = []
        for startId, geomId in cur:
            if geomId in ExcludeGeomIds: continue                 # geometry already exist, skip
            expGClist.append((geomId, startId))
            if len(expGClist)==jobs: break                        # got everything needed

    assert expGClist, "No Exportable geometries found"            # preventing null exports
    return expGClist


def ExportCalc(dB, geomId, calcId, pesaDir, expDir, ComTemplate, StartId, BaseSuffix):
    print 'Exporting Job No {} with GeomId {}'.format(BaseSuffix, geomId)
    with sqlite3.connect(dB) as con:
        con.row_factory=sqlite3.Row
        cur = con.cursor()
        cur.execute('SELECT * from Geometry WHERE Id=?',(geomId,))
        GeomRow = cur.fetchone()
        cur.execute('SELECT * from CalcInfo WHERE Id=?',(calcId,))
        InfoRow = cur.fetchone()
        if ComTemplate:                     # if template given use that, o/w use from calcinfo table
            with open(ComTemplate,'r') as f: InpTempl = f.read()
        else:
            InpTempl = InfoRow["InpTempl"]

        if StartId:                         # non-zero StartId , collect necessary things from calc table
            cur.execute('SELECT * from Calc WHERE Id=?',(StartId,))
            calcRow = cur.fetchone()
            StartGId = calcRow["GeomId"]
            StartDir = calcRow["Dir"]
            c,a,b = StartDir.split("/")     # StartDir -> GeomData/geom1/multi1; StartBaseName -> multi1-geom1
            StartBaseName = "{}-{}".format(b,a)
        else:
            StartGId = 0

    BaseName = "{}{}-geom{}-".format(InfoRow["Type"], calcId, geomId) + BaseSuffix
    ExportDir = expDir + "/" + BaseName
    os.makedirs(ExportDir)

    fCalc = '{}/{}.calc_'.format(ExportDir,BaseName) # `_` at the end means job not yet done, will be removed after successful run
    fXYZ  = '{}/{}.xyz'.format(ExportDir,BaseName)
    genCalcFile(calcId,geomId,InfoRow["Type"],BaseName,StartGId,fCalc)
    geomObj.createXYZfile(GeomRow, filename = fXYZ)  #< -- geometry file is created from outside

    if StartId:                       # copy wavefunc if start id is present
        if os.path.isdir(StartDir):   # not in zipped format, copy it to a new name
            shutil.copy(StartDir+ "/%s.wfu"%StartBaseName, ExportDir+"/%s.wfu"%BaseName )
        else:                         # file is in tar
            tar = tarfile.open(StartDir+".tar.bz2")
            tar.extract("./%s.wfu"%StartBaseName, path=ExportDir) # open tar file and rename it
            os.rename(ExportDir+"/%s.wfu"%StartBaseName, ExportDir+"/%s.wfu"%BaseName)

    txt = InpTempl.replace("$F$",BaseName)
    # generate molpro input file
    fInp = '{}/{}.com'.format(ExportDir,BaseName)
    with open(fInp,'w') as f: f.write(txt)
    return BaseName



def ImportNearNbrJobs(dB, expFile, pesaDir, iGl, isDel, isZipped, logger):
    # imports jobs from a given export.dat file

    exportDir = os.path.abspath(os.path.dirname(expFile))   # get the main export directory
    exportId  = re.findall('Export(\d+)-', exportDir)[0]     # get the export id, from the directroy name
    # so it seems the export.dat is really not needed to import a job, just the path directory is required

    with sqlite3.connect(dB) as con:
        cur = con.cursor()
        cur.execute('SELECT Status FROM Exports WHERE Id=?',(exportId,))         # check if the export id is open for import
        exp_row = cur.fetchone()
        assert exp_row,        "Export Id = {} not found in data base".format(exportId)
        assert exp_row[0] ==0, "Export Id = {} is already closed.".format(exportId)
        importCount = 0

        # now obtain list of jobs which can be imported.
        cur.execute("SELECT GeomId,CalcDir FROM ExpCalc where ExpId=?",(exportId,))
        for geomId, calcDir in cur.fetchall():
            dirFull = exportDir + "/" + calcDir                     # ab initio directory
            calcFile= "{0}/{1}/{1}.calc".format(exportDir, calcDir) # calcfile name
            if os.path.isfile(calcFile):                            # is this job successful?

                logger.info("Importing ...{}".format(dirFull))
                ImportCalc(cur,dirFull,calcFile,pesaDir, ignoreList=iGl, zipped=isZipped)

                cur.execute('DELETE FROM ExpCalc WHERE ExpId=? AND GeomId=? ',(exportId,geomId))
                importCount += 1

                if isDel:
                    logger.info("Deleting directory {}".format(dirFull))
                    shutil.rmtree(dirFull)

        cur.execute("UPDATE Exports SET ImpDT=strftime('%H:%M:%S %d-%m-%Y', datetime('now', 'localtime')) WHERE Id=?",(exportId,))
        cur.execute("SELECT count(*) FROM ExpCalc WHERE ExpId=?",(exportId,))

        if cur.fetchone()[0]==0:
            cur.execute("UPDATE Exports SET Status=1 WHERE Id=?",(exportId,))
            logger.info('Export Id={} is now closed.'.format(exportId))
            if isDel:
                logger.info("Deleting directory {}".format(exportDir))
                shutil.rmtree(exportDir)
        else :
            logger.info('Export Id={} is not closed.'.format(exportId))
        logger.info("{} Job(s) have been successfully imported.\n".format(importCount))



def ImportCalc(cur,calcDir,calcFile,pesaDir,ignoreList, zipped):

    with open(calcFile,'r') as f:
        txt = f.read().split("\n")[1:] #first line comment
    dCalc = dict([map(str.strip, i.split(":")) for i in txt])

    a,b,_ = dCalc['Basename'].split('-') # a base name `multinact2-geom111-1` will go `GeomData/geom111/multinact2`
    destCalcDir = "{}/{}/{}".format(pesaDir, b, a)
    fRes = "{}/{}.res".format(calcDir, dCalc['Basename'])
    sResults = parseResult(fRes)
    if not os.path.exists(destCalcDir):  os.makedirs(destCalcDir)  # this should not exists though

    tcalc = (dCalc["GeomId"],dCalc["CalcId"], destCalcDir, dCalc["StartGId"],sResults)
    cur.execute("INSERT INTO Calc (GeomId,CalcId,Dir,StartGId,Results) VALUES (?, ?, ?, ?, ?)", tcalc)

    for iFile in glob("{}/*.*".format(calcDir)):
        if os.path.splitext(iFile)[1][1:] in ignoreList: continue                   # copy all file except for ones ignore list
        oFile = destCalcDir + "/" + re.sub('-\d+','',os.path.basename(iFile))   # rename file, `multinact2-geom111-1` -> `multinact2-geom111`
        shutil.copy(iFile, oFile)
    if zipped:                                                                  # archive the folder if specified
        shutil.make_archive(destCalcDir, 'bztar', root_dir=destCalcDir, base_dir='./')
        shutil.rmtree(destCalcDir)


def createRunJob(molInfo, file):

    txt = '''#!/usr/bin/python

import os, subprocess
from datetime import datetime

def writeLog(fLog, msg, cont=False): # writes to the log file
    if not cont :
        msg = '{{:.<90}}'.format(datetime.now().strftime("[%d-%m-%Y %I:%M:%S %p]     ") + msg)
    else:
        msg+='\\n'
    fLog.write(msg)
    fLog.flush()


# first open export.dat file and collect information about exported jobs
with open("export.dat",'r') as f:
    expDirs = f.read().split("\\n",1)[1].split()[1:]

mainDirectory = os.getcwd()
fLog = open("run.log","a")

# now execute each job
for RunDir in expDirs:
    if os.path.isfile("{{0}}/{{0}}.calc".format(RunDir)):
        writeLog(fLog, "Job already done for "+RunDir, True)
        continue
    elif os.path.isfile("{{0}}/{{0}}.calc_".format(RunDir)):
        writeLog(fLog, "Running Job for "+RunDir)
    else:
        raise Exception("No '.calc' or '.calc_' file found in {{}}".format(RunDir))
    fComBaseFile = RunDir+".com"

    os.chdir(RunDir)
    exitcode = subprocess.call(["molpro",fComBaseFile, "-d", "{}", "-W .", "-n", "{}"] + {})
    os.chdir(mainDirectory)

    if exitcode == 0:
        writeLog(fLog, "Job Successful.", True)
        os.rename( "{{0}}/{{0}}.calc_".format(RunDir), "{{0}}/{{0}}.calc".format(RunDir))    # rename .calc_ file so that it can be imported
    else:
        writeLog(fLog, "Job Failed.", True)

writeLog(fLog, "All Jobs Completed\\n")
writeLog(fLog, "."*70, True)
fLog.close()

'''.format(molInfo['scrdir'], molInfo['proc'], molInfo['extra'])
    with open(file, 'w') as f: f.write(txt)
    os.chmod(file,0766)