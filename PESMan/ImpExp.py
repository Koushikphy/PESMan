from __future__ import print_function
import re
import os
import shutil
import tarfile
import sqlite3
from glob import glob
from geometry import geomObj
# initiate the geometry object inside the geometry file  and call the methods from there
# this is benificial for normal mode as the code doesn't have to initite the object for every geometry


def parseResult(file):
    # Collects any valid number and returns the result as a string
    with open(file, 'r') as f: txt = f.read()
    txt = txt.replace('D','E')
    res = re.findall(r"(?:(?<=^)|(?<=\s))([+-]?\d+(?:\.\d*)?(?:[eE][+-]?\d+)?)(?=\s|$|\n|\r\n)", txt)
    return ' '.join(res)


def genCalcFile(CalcId,GeomId,CalcName,Basename,sid,fileName,Desc=""):
    # Creates the calc files 
    txt = """# This file is automatically generated.Do not edit, unless you are sure of what you are changing.
    CalcId   : {}
    GeomId   : {}
    Name     : {}
    Basename : {}
    StartGId : {}
    Desc     : {}""".format(CalcId,GeomId,CalcName,Basename,sid,Desc)
    with open(fileName, "w") as f:
        f.write(txt)



def ExportNearNbrJobs(dB, calcId, jobs, exportDir,pesDir, templ, gidList, sidList, depth, constDb, includePath, molInfo):
    # Main export function that exports a given number of jobs for a specified calcid type
    # collect the geomid that are exportable and the calc table id which will be used as their startid
    if calcId > 1: # Mrci or nact export
        ExpGeomList = GetExpMrciNactJobs(dB,calcId, jobs, constDb)
    else:
        ExpGeomList = GetExpGeomNearNbr(dB,calcId, gidList, sidList, jobs, depth, constDb, includePath)


    # The context manager prevents the database from commiting in case of error, use try-except for further control
    with sqlite3.connect(dB) as con:
            con.row_factory=sqlite3.Row
            cur = con.cursor()
            cur.execute('SELECT * from CalcInfo WHERE Id=?',(calcId,))
            InfoRow = cur.fetchone()
            assert InfoRow, "No Info found for CalcId={} found in data base".format(calcId)
            # insert into database one row and use the id as export id
            cur.execute("INSERT INTO Exports (CalcId) VALUES (?)", (calcId,))
            exportId = cur.lastrowid

            ExpDir = "{}/Export{}-{}{}".format(exportDir, exportId, InfoRow["type"], calcId)
            # remove the export directory if already exists, may have created from some failed export. shouldn't have happened
            if os.path.exists(ExpDir):  shutil.rmtree(ExpDir)
            os.makedirs(ExpDir)

            expDirs = []
            for ind, (GeomId,StartCalcId) in enumerate(ExpGeomList, start=1):
                print('Exporting Job No {} with GeomId {}'.format(ind, GeomId))
                bName = ExportCalc(cur, dB, GeomId, calcId,pesDir,ExpDir, InfoRow, templ,StartId=StartCalcId, BaseSuffix=str(ind))
                expDirs.append(bName)


            # update the export table and expcalc tables with the exported jobs
            expGeomIds = [i for i,_ in ExpGeomList]
            cur.execute("UPDATE Exports SET NumCalc=?, ExpDT=strftime('%H:%M:%S %d-%m-%Y', datetime('now', 'localtime')), ExpGeomIds=? WHERE Id=?", (len(expDirs), ' '.join(map(str,expGeomIds)), exportId))

            lExpCalc = [[exportId,calcId, i,j] for i,j in zip(expGeomIds, expDirs)]
            cur.executemany("INSERT INTO ExpCalc (ExpId,CalcId,GeomId,CalcDir) VALUES (?,?,?,?)",lExpCalc)

            
            fExportDat = ExpDir + "/export.dat"                       # save the export id and exported directories in export.dat file
            with open(fExportDat,'w') as f:
                f.write("# Auto generated file. Please do not modify\n"+ ' '.join(map(str,[exportId]+expDirs)))

            os.chmod(fExportDat,0444)                                  # change mode of this file to read-only to prevent accidental writes

            fPythonFile =   "{}/RunJob{}.py".format(ExpDir, exportId)  # save the python file that will run the jobs
            createRunJob(molInfo, fPythonFile)
            print("PESMan export successful: Id {} with {} job(s) exported".format(exportId, len(ExpGeomList)))
            return ExpDir, exportId, expDirs



def GetExpGeomNearNbr(dB,calcId,GidList=[],SidList=[],jobs=1,maxDepth=0,ConstDb="",inclPath=False):
    # Get the exportable geometries and their start id for mulit jobs, returns 
    with sqlite3.connect(dB) as con:
        cur = con.cursor()

        # get jobs that is already done and add to excludegeomlist
        cur.execute("SELECT GeomId,Id FROM Calc WHERE CalcId=?",(calcId,))
        DictCalcId  = dict(cur.fetchall())
        CalcGeomIds = set(DictCalcId.iterkeys())
        ExcludeGeomIds = CalcGeomIds.copy()

        cur.execute("SELECT GeomId FROM ExpCalc WHERE CalcId=?",(calcId,))
        ExcludeGeomIds.update([i[0] for i in cur])

    #--------------------------------------------------------------------------------
        # lPrblmGeomIds = []
        # ExcludeGeomIds.update(lPrblmGeomIds)
    #--------------------------------------------------------------------------------

        if GidList:
            g, s= len(GidList), len(SidList)
            if g>s: SidList += [-1 for _ in range(g-s)] # fill SidList if some missing
            DictStartId = dict(zip(GidList, SidList))   # create a dict of start ids

        cond = []
        if GidList:      cond.append( 'id in (' + ",".join(map(str, GidList)) + ')')     #include gidlist
        if ConstDb:      cond.append( '(' + ConstDb + ')')                               #include constraint
        if not inclPath: cond.append( "( tags NOT LIKE '%path%')")                       #exclude pathological

        cond = ' where ' + ' and '.join(cond) if cond else ''
        cur.execute('SELECT Id,Nbr FROM Geometry' + cond)


        expGClist = []                                            # list that collects the exportable jobs info
        fullGeomList = []                                         # a naive approach: store all the missed geometries
        for GeomId, nbrList in cur:
            if GeomId in ExcludeGeomIds: continue                 # geometry already exist, skip
            if GidList and DictStartId[GeomId]>=0:                # negetive start id will go to main neighbour searching
                nbrId = DictStartId[GeomId]                       # i.e. 0 or positive startid given
                if not nbrId :                                    # 0 startid nothing to do here
                    expGClist.append([GeomId, 0])
                elif nbrId in CalcGeomIds :                       # positive start id, include if calculation is already done
                    expGClist.append([GeomId, DictCalcId[nbrId]])
                if len(expGClist)==jobs: 
                    return expGClist                              # got all the geometries needed
                continue

            nbrList = map(int, nbrList.split())                   # Care ful about integer mapping
            nbrId = nbrList[0]                                    # for this initial loop only consider first neighbour

            if nbrId in CalcGeomIds:
                expGClist.append([GeomId, DictCalcId[nbrId]])     # got one match 
                if len(expGClist)==jobs:
                    return expGClist
                continue
            fullGeomList.append([GeomId, nbrList])
        
        #Get allowed depth. Provided every nbr list has same number of elements. This may be poor, do something better
        depth = maxDepth if maxDepth else len(fullGeomList[0][1]) if fullGeomList else 0  
        exportedGeom = set([])
        for d in range(1,depth):                                   # depth loop starting from 1 to end, 
            for GeomId, nbrList in fullGeomList:
                if GeomId in exportedGeom: continue                

                nbrId = nbrList[d]                                 # get d-th neighbour
                if nbrId in CalcGeomIds:
                    expGClist.append([GeomId, DictCalcId[nbrId]])  # got one match now don't search for any other neighbours
                    if len(expGClist)==jobs:     
                        return expGClist
                    exportedGeom.add(GeomId)

    assert len(expGClist), "No Exportable geometries found"         # preventing null exports
    return expGClist



def GetExpMrciNactJobs(dB,calcId,jobs=50,ConstDb=""):

    with sqlite3.connect(dB) as con:
        cur = con.cursor()

        cur.execute("SELECT GeomId FROM Calc WHERE CalcId=?",(calcId,))
        CalcGeomIds = set(cur.fetchall())
        ExcludeGeomIds = CalcGeomIds.copy()  # jobs that is already done.

        cur.execute("SELECT GeomId FROM ExpCalc WHERE CalcId=?",(calcId,))
        ExcludeGeomIds.update([i[0] for i in cur])
    #--------------------------------------------------------------------------------
        # lPrblmGeomIds = []
        # ExcludeGeomIds.update(lPrblmGeomIds)
    #--------------------------------------------------------------------------------
        if ConstDb:
            cur.execute("SELECT Id FROM Geometry where " + ConstDb )
            ConstGeomIds = set([i[0] for i in cur.fetchall()])

        cur.execute("SELECT Id,GeomId FROM Calc WHERE CalcId = 1")

        expGClist = []
        for StartId, GeomId in cur:
            if ConstDb and (GeomId not in ConstGeomIds):              # this is a small list so checking it before excludelist
                continue
            if (GeomId not in ExcludeGeomIds):
                expGClist.append([GeomId, StartId])
                if len(expGClist)==jobs:                               # got everything needed
                    break

    assert len(expGClist), "No Exportable geometries found"            # preventing null exports
    return expGClist



def ExportCalc(cur, Db,GeomId,calcId,DataDir,ExpDir, InfoRow, ComTemplate="",StartId=0,BaseSuffix=""):

    # get the geometry
    cur.execute('SELECT * from Geometry WHERE Id=?',(GeomId,))
    GeomRow = cur.fetchone()

    # if template given use that, o/w use from calcinfo table
    if ComTemplate:
        with open(ComTemplate,'r') as f: InpTempl = f.read()
    else:
        InpTempl = InfoRow["InpTempl"]

    if StartId:                     #non-zero StartId , collect necessary things from calc table
        cur.execute('SELECT * from Calc WHERE Id=?',(StartId,))
        calcRow = cur.fetchone()
        StartGId = calcRow["GeomId"]
        StartDir = calcRow["Dir"]
        c,a,b = StartDir.split("/") # StartDir -> GeomData/geom1/multi1; StartBaseName -> multi1-geom1
        StartBaseName = "{}-{}".format(b,a)
    else:
        StartGId = 0

    # decide basename needed for generated files and create the main export directory
    BaseName = "{}{}-geom{}-".format(InfoRow["Type"], calcId, GeomId) + BaseSuffix
    ExportDir = ExpDir + "/" + BaseName
    os.makedirs(ExportDir)

    # for calc file, we will generate it as .calc_ <--- note extra underscore at end
    # this is to safegaurd against faulty imports. this should be renamed to .calc upon successful run
    fCalc = ExportDir + "/" + BaseName + ".calc_" 
    fXYZ  = ExportDir + "/" + BaseName + ".xyz"
    genCalcFile(calcId,GeomId,InfoRow["Type"],BaseName,StartGId,fCalc)
    geomObj.createXYZfile(GeomRow, filename = fXYZ)  #< -- geometry file is created from outside


    if StartId:                       # copy wavefunc if start id is 
        if os.path.isdir(StartDir):   # not in zipped format, copy it to a new name
            shutil.copy(StartDir+ "/%s.wfu"%StartBaseName, ExportDir+"/%s.wfu"%BaseName )
        else:                         # file is in tar
            tar = tarfile.open(StartDir+".tar.bz2")
            tar.extract("./%s.wfu"%StartBaseName, path=ExportDir) # open tar file and rename it
            os.rename(ExportDir+"/%s.wfu"%StartBaseName, ExportDir+"/%s.wfu"%BaseName)

    txt = InpTempl.replace("$F$",BaseName)
    # generate molpro input file
    fInp = ExportDir + "/" + BaseName + ".com" 
    with open(fInp,'w') as f: f.write(txt)

    return BaseName



def ImportNearNbrJobs(dB, expFile, DataDir, iGl, isDel, isZipped):
    # imports jobs from a given export.dat file

    ExportDir = os.path.abspath(os.path.dirname(expFile))
    # we only need export directory and id, everything else will be read from the database
    # so it seems a export.dat is really not needed to import a job
    with open(expFile,'r') as f: # read the export.dat and collect export id
        exportId = f.read().split("\n",1)[1].split(" ")[0] #skip first line and read 1st number as export id

    with sqlite3.connect(dB) as con:
            cur = con.cursor()
            cur.execute('SELECT Status FROM Exports WHERE Id=?',(exportId,))         # check if the export id is open for import
            exp_row = cur.fetchone()
            assert exp_row,        "Export Id = {} not found in data base".format(exportId)
            assert exp_row[0] ==0, "Export Id = {} is already closed.".format(exportId)
            importCount = 0

            # now obtain list of jobs which can be imported.
            cur.execute("SELECT GeomId,CalcDir FROM ExpCalc where ExpId=?",(exportId,))
            for geomId, calcDir in cur.fetchall():
                if os.path.isfile("{0}/{1}/{1}.calc".format(ExportDir, calcDir)):   # is this job successful?

                    dirFull = ExportDir + "/" + calcDir
                    cFiles = glob(dirFull+"/*.calc")
                    # assert len(cFiles)==1, "{} must have 1 calc file but has {}.".format(dirFull, len(cFiles))

                    print("Importing ...{}... ".format(dirFull), end='')
                    ImportCalc(cur,dirFull,cFiles[0],DataDir, ignoreList=iGl, zipped=isZipped)
                    print("done")

                    cur.execute('DELETE FROM ExpCalc WHERE ExpId=? AND GeomId=? ',(exportId,geomId))
                    importCount += 1
                    
                    if isDel: 
                        print("Deleting directory {}".format(dirFull))
                        shutil.rmtree(dirFull)

            cur.execute("UPDATE Exports SET ImpDT=strftime('%H:%M:%S %d-%m-%Y', datetime('now', 'localtime')) WHERE Id=?",(exportId,))

            cur.execute("SELECT count(*) FROM ExpCalc WHERE ExpId=?",(exportId,))

            if cur.fetchone()[0]==0:
                cur.execute("UPDATE Exports SET Status=1 WHERE Id=?",(exportId,))
                print('Export Id={} is now closed.'.format(exportId))
                if isDel: shutil.rmtree(ExportDir)
            else :
                print('Export Id={} is not closed.'.format(exportId))

            print("{} Job(s) have been successfully imported.".format(importCount))



def ImportCalc(cur,CalcDir,CalcFile,DataDir,ignoreList, zipped):

    with open(CalcFile,'r') as f:
        txt = f.read().split("\n")[1:] #first line comment
    dCalc = dict([map(str.strip, i.split(":")) for i in txt])

    a,b,_ = dCalc['Basename'].split('-') # a base name `multinact2-geom111-1` will go `GeomData/geom111/multinact2`
    DestCalcDir = DataDir+"/{}/{}".format(b,a)
    fRes = "{}/{}.res".format(CalcDir, dCalc['Basename'])
    sResults = parseResult(fRes)
    if not os.path.exists(DestCalcDir):  os.makedirs(DestCalcDir)

    tcalc = (dCalc["GeomId"],dCalc["CalcId"], DestCalcDir, dCalc["StartGId"],sResults)
    cur.execute("INSERT INTO Calc (GeomId,CalcId,Dir,StartGId,Results) VALUES (?, ?, ?, ?, ?)", tcalc)

    for iFile in glob("{}/*.*".format(CalcDir)):
        if os.path.splitext(iFile)[1] in ignoreList:  # copy all file except for ones ignore list
            continue
        oFile = DestCalcDir + "/" + re.sub('-\d+','',os.path.basename(iFile)) # `multinact2-geom111-1` -> `multinact2-geom111`
        shutil.copy(iFile, oFile)
    if zipped: # archive the folder if specified
        shutil.make_archive(DestCalcDir, 'bztar', root_dir=DestCalcDir, base_dir='./')
        shutil.rmtree(DestCalcDir)



def createRunJob(molInfo, file):
    
    txt = '''#!/usr/bin/python
# -*- coding: utf-8 -*-

import os
import subprocess
from datetime import datetime


def writeLog(fLog, msg, cont=False): # writes to the log file
    if not cont : 
        msg = '{{:.<90}}'.format(datetime.now().strftime("[%d-%m-%Y %I:%M:%S %p]     ") + msg)
    else:
        msg+='\\n'
    fLog.write(msg)
    fLog.flush()


def runExportedCalcs(scrDir, proc, extra):
    """ Run or continue a series of exported jobs."""

    # first open export.dat file and collect information about exported jobs
    with open("export.dat",'r') as f:
        expDirs = f.read().split("\\n",1)[1].split()[1:]

    mainDirectory = os.getcwd()
    fLog = open("run.log","a")

    # now execute each job
    for RunDir in expDirs:
        if os.path.isfile("{{0}}/{{0}}.calc".format(RunDir)): 
            writeLog(fLog, "Job already done for "+RunDir, True)
            continue
        elif os.path.isfile("{{0}}/{{0}}.calc_".format(RunDir)):
            writeLog(fLog, "Running Job for "+RunDir)
        else:
            raise Exception("No '.calc' or '.calc_' file found in {{}}".format(RunDir))
        fComBaseFile = RunDir + ".com"

        os.chdir(RunDir)

        exitcode = subprocess.call(["molpro", "-d", scrDir, "-W .", "-n", proc, fComBaseFile] + extra)
        os.chdir(mainDirectory)

        if exitcode == 0:
            writeLog(fLog, "Job Successful.", True)
            os.rename( "{{0}}/{{0}}.calc_".format(RunDir), "{{0}}/{{0}}.calc".format(RunDir))    # rename .calc_ file so that it can be imported

        else:
            writeLog(fLog, "Job Failed.", True)

    writeLog(fLog, "All Jobs Completed\\n")
    writeLog(fLog, "."*70, True)
    fLog.close()


if __name__ == '__main__':
    runExportedCalcs('{}', '{}', {})

'''.format(molInfo['scrdir'], molInfo['proc'], molInfo['extra'])
    with open(file, 'w') as f:
        f.write(txt)
    os.chmod(file,0766)