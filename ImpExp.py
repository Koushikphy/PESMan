#!/usr/bin/python
# -*- coding: utf-8 -*-
""" This module contains basic subroutines required for general import/export. """

import sqlite3
import os
import sys
import os.path
import shutil
import geometry
import misc
import re
import subprocess
import bisect
import parse
import soeigen

def GenCalcFile(CalcId,GeomId,CalcName,Record,Basename,Desc="",Aux=""):

    sheader = """
# This file is automatically generated.
# The defaults are usually sufficient for import.
# Do not edit, unless you are sure of what you are changing.
#
"""
    scalc = "CalcId   : " + str(CalcId)
    sgeom = "GeomId   : " + str(GeomId)
    sname = "Name     : " + str(CalcName)
    srec  = "Record   : " + str(Record)
    sbase = "Basename : " + str(Basename)
    sdesc = "Desc     : " + str(Desc)
    saux  = "Aux      : " + str(Aux)

    return "\n".join([sheader,scalc,sgeom,sname,srec,sbase,sdesc,saux]) + "\n"

def ParseFile(sfile,lkeys):
   """ A generic parser which can parse key : value pairs from any string and return a dictionary of parsed options """
   def remove_comments(s):
       p = s.find("#")
       if p >=0:
          snew = s[0:p]
       else:
          snew = s
       return snew.strip()
   ls0 = [x.strip() for x in sfile.splitlines() if x.strip()]
   ls1 = [tuple(x.split(":")) for x in ls0 if remove_comments(x)]
   for t in ls1:
      assert (len(t) == 2)
   ls2 = [(x.strip(),y.strip()) for (x,y) in ls1]
   lparse = { k.upper():v for (k,v) in ls2 }
   for key in lkeys:
      assert( key.upper() in lparse )
   assert (len(lparse) == len(lkeys))
   return lparse


def GetResults(sres,fres):
    """ Grep the results from results file and return a tuple """
    lres = sres.split()
    with open(fres,'r') as f:
       sfile = f.read()
       f.close()
    lmatch = []
    for sr in lres:
      r = re.compile(sr + '\s+([-+]?[0-9]*\.[0-9]+)')
      sg = r.search(sfile)
      if sg:
         # match found
         lmatch.append(sg.group(1))
      else:
         # do not try to find some match for now
         #raise Exception("Match not found" + sr + "in file" + fres)
         pass
    return " ".join(lmatch)


###############################################################################################
# The following definition in the code is added by Bijit:

def GetResultsNact(fres):
      """ Grep the results from results file and return a list of tuples """
      f = open(fres,'r')
      i=0
      while i<4:
        f.readline()
	i += 1
      str12 = f.readline()
      str12 += f.readline()
      str12 += f.readline()
      str12 = str12.split()
      str12 = [i.replace('D','E') for i in str12]
      #str12 = [float(i) for i in str12]
      i=0
      while i<4:
        f.readline()
	i += 1
      str13 = f.readline()
      str13 += f.readline()
      str13 += f.readline()
      str13 = str13.split()
      str13 = [i.replace('D','E') for i in str13]
      #str13 = [float(i) for i in str13]
      i=0
      while i<4:
        f.readline()
	i += 1
      str23 = f.readline()
      str23 += f.readline()
      str23 += f.readline()
      str23 = str23.split()
      str23 = [i.replace('D','E') for i in str23]
      #str23 = [float(i) for i in str23]
      f.close()
      lresults = str12 + str13 + str23
      return " ".join(lresults)

############################### Modified portion ends here! ###################################
###############################################################################################


def ImportCalc(Db,CalcDir,CalcFile,DataDir,Verbose=False,Check=False):
   """ Import the results of a calculation.
       Db       -- data base to import into
       CalcDir  -- directory where the results of calculation can be found
       CalcFile -- the .calc file of the calculation from which information is collected.
                   NOTE : you may also modify .calc to make necessary changes,
                          such as altering the record number where orbitals are stored
                          adding notes and further files to be copied etc,.
       DataDir  -- the directory where the results should be copied to.
   """

   # CalcDir should have read access
   # CalcFile should have read access
   # DataDir must have write access
   misc.CheckDirAccess(CalcDir,bRead=True,bAssert=True)
   misc.CheckFileAccess(CalcFile,bRead=True,bAssert=True)
   misc.CheckDirAccess(DataDir,bRead=False,bAssert=True)

   # Db must have read as well as write access
   misc.CheckFileAccess(Db,bRead=True,bAssert=True)
   misc.CheckFileAccess(Db,bRead=False,bAssert=True)

   # parse calcfile and get basename
   # this is to identify the files to be imported.
   with open(CalcFile,'r') as f:
      sCalc = f.read()
      f.close()
   dCalc = ParseFile(sCalc,["calcid","name","record","desc","geomid","basename","aux"])

   # sanity check the parsed details first
   assert( dCalc["CALCID"].isdigit() and dCalc["GEOMID"].isdigit() )
   dCalc["CALCID"] = int(dCalc["CALCID"])
   dCalc["GEOMID"] = int(dCalc["GEOMID"])
   lrec = dCalc["RECORD"].split(".",1)
   # also accept default file name 2
   if len(lrec) == 2:
      assert (lrec[0].isdigit() and lrec[1].isdigit())
      rec,fil = int(lrec[0]),int(lrec[1])
   elif len(lrec) == 1:
      assert (lrec[0].isdigit())
      rec,fil = int(lrec[0]),2
   else:
      raise Exception("Unknown entry in .calc file: " + dCalc["RECORD"])
   dCalc["RECORD"] = str(rec)+"."+str(fil) # reconstruct it again

   # construct full path names of different files using basename
   BaseName = dCalc["BASENAME"]
   filepfx = CalcDir + "/" + BaseName + "."
   (fXYZ,fWfu,fInp,fOut,fRes,fCalc,fPun,fXml) = tuple(filepfx + x for x in ["xyz","wfu","com","out","res","calc","pun","xml"])

   # all files must exist and be readable
   # NOTE: relax this a bit to stop producing unnecessary errors
   misc.CheckFileAccess(fXYZ,bRead=True,bAssert=True)
   misc.CheckFileAccess(fWfu,bRead=True,bAssert=True)
   misc.CheckFileAccess(fInp,bRead=True,bAssert=True)
   misc.CheckFileAccess(fOut,bRead=True,bAssert=True)
   misc.CheckFileAccess(fRes,bRead=True,bAssert=True)

   # these files need not be there
   # if they are there, they will be copied
   # misc.CheckFileAccess(fPun,bRead=True,bAssert=True)
   # misc.CheckFileAccess(fXml,bRead=True,bAssert=True)

   # calc file, in some cases, need not be there.
   # as it may happen when doing manual imports
   # this is better handled by calling routines
   # however, if it is there, we must make sure that
   # its contents match with that of CalcFile.
   if misc.CheckFileAccess(fCalc,bRead=True,bAssert=False):
      with open(fCalc,'r') as f:
         sCalcImport = f.read()
         f.close()
         assert (sCalc == sCalcImport)

   # now we are ready to open the data base and add record to Calc table
   # at this point, we will assume that, validity of this step has been
   # properly checked by calling routine.
   try:

      con = sqlite3.connect(Db)
      # use row factory which is far better and has dictionary-like access to data
      con.row_factory = sqlite3.Row
      
      # define cursor
      cur = con.cursor()

      #query db for geometry and calctype
      GeomId = dCalc["GEOMID"]
      CalcId = dCalc["CALCID"]

      cur.execute('SELECT * from Geometry WHERE Id=?',(GeomId,))
      GeomRow  = cur.fetchall()
      assert (len(GeomRow) == 1)
      cur.execute('SELECT * from CalcInfo WHERE Id=?',(CalcId,))
      InfoRow  = cur.fetchall()
      assert (len(InfoRow) == 1)

      GeomRow = GeomRow[0]
      InfoRow = InfoRow[0]

      # construct geometry object for this geometry and produce its xyz file
      gobj = geometry.Geometry(sr=GeomRow["sr"],cr=GeomRow["cr"],theta=GeomRow["theta"],id=GeomRow["id"])
      sXYZ = gobj.to_xyzstr()

      # xyz file also must match -- just to make sure
      # ideally, the comment fields in xyz files may not match.
      with open(fXYZ,'r') as f:
         sXYZcalc = f.read()
         f.close()
         assert (sXYZ == sXYZcalc)

      # now xyz and calc files match each other, so geometry is correct
      # names also must match
      assert (dCalc["NAME"] == InfoRow["name"])

      # check if different record is being used
      #if (dCalc["RECORD"] != InfoRow["orbrec"]):
      #   print "different record number from templaet is being used; hope you are advanced user!"

      # check if this calc already exists for this geometry; this is error.
      # to add a calc which already exists, you will need to remove this first.
      cur.execute("SELECT * FROM CALC where GeomId=? AND CalcId=?",(GeomId,CalcId))
      if cur.fetchall():
         raise Exception("The calculation being imported already exists in the Database")
      
      ##################################################################################
      # The following part of the code is added by Bijit:

      # collect results from the files and add it to data base
      # for nacts the greping procedure from res file is different
      # calcid == 3 corresponds to ana-nact calcs
      if dCalc["CALCID"] == 3:           
         sResults = GetResultsNact(fRes)
      else:
         sResults = GetResults(InfoRow["resvars"],fRes)

      ############################### Modified portion ends here! #####################
      #################################################################################

      # The BaseName supplied in .calc file SHOULD not be used in destination directory
      # even if it matches our final destination base name.
      # we change base name now - this is what we use in data base
      BaseNameDb = InfoRow["Type"] + str(CalcId) + "-" + "geom" + str(GeomId)
      fDbWfu = BaseNameDb + ".wfu"
      fDbInp = BaseNameDb + ".com"
      fDbOut = BaseNameDb + ".out"
      fDbRes = BaseNameDb + ".res"
      fDbPun = BaseNameDb + ".pun"
      fDbXml = BaseNameDb + ".xml"
      fDbXYZ = BaseNameDb + ".xyz"
      fDbCalc = BaseNameDb + ".calc"

      # we will not copy calc file, it is neither necessary nor useful.
      # TODO: it may be better to generate a new .calc file and save it.
      #       it will be useful later to reimport all calculations.

      # Define DestDir where the result will go;
      # Create them before database is modified
      DestGeomDir = DataDir + "/" + "geom" + str(GeomId)
      if os.path.exists(DestGeomDir):
         if os.path.isdir(DestGeomDir):
            # check if it is writable
            misc.CheckDirAccess(DestGeomDir,bRead=False,bAssert=True)
         else:
            raise Exception(DestGeomDir + " is not a directory")
      else:
         # create it
         os.mkdir(DestGeomDir,0775)
      
      DestCalcDir = DestGeomDir + "/" + InfoRow["type"] + str(CalcId)
      if os.path.exists(DestCalcDir):
         # this is an error -- can not import if it already exists
         raise Exception(DestCalcDir + " already exists at Destination ")
      else:
         # create it now
         os.mkdir(DestCalcDir,0775)
       
      DestDir = os.path.relpath(DestCalcDir,start=DataDir)
      
      # collect all the information into a tuple for insertion to Calc data base
      # we will now insert Dir field to be relative to DataDir
      tcalc = (GeomId,CalcId,DestDir,fDbWfu,dCalc["RECORD"],fDbInp,\
               fDbOut,fDbRes,dCalc["AUX"],sResults,dCalc["DESC"])

      sSOMatelem = parse.parseso(fOut)
      sSOener = soeigen.soeigen(sSOMatelem,sResults)


      try:
        cur.execute("""INSERT INTO Calc (GeomId,CalcId,Dir,WfnFile,OrbRec,InputFile,
                       OutputFile,ResultFile,AuxFiles,Results,Desc)
                       VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""", tcalc)

        cur.execute("SELECT id FROM CALC where GeomId=? and calcid = ?",(GeomId,CalcId))
        idrow = cur.fetchall()
        assert (len(idrow) == 1)
        idrow = idrow[0]

        tres = (GeomId,idrow["id"],sResults,sSOMatelem,sSOener)

        cur.execute("""INSERT INTO Results (GeomId,CalcId,Energy,Somatel,Soener)
                       VALUES (?, ?, ?, ?, ?)""", tres)

        # Now we copy into DestCalcDir as different files
        # DestCalcDir will have full path name
        # if INSERT fails, this code is not executed
        # in the most unlikely case, the directory would not be added to data base
        shutil.copy(fXYZ,DestCalcDir + "/" + fDbXYZ)
        shutil.copy(fWfu,DestCalcDir + "/" + fDbWfu)
        shutil.copy(fInp,DestCalcDir + "/" + fDbInp)
        shutil.copy(fOut,DestCalcDir + "/" + fDbOut)
        shutil.copy(fRes,DestCalcDir + "/" + fDbRes)
        shutil.copy(fCalc,DestCalcDir + "/" + fDbCalc)
        if misc.CheckFileAccess(fPun,bRead=True,bAssert=False):
           shutil.copy(fPun,DestCalcDir + "/" + fDbPun)
        if misc.CheckFileAccess(fXml,bRead=True,bAssert=False):
           shutil.copy(fXml,DestCalcDir + "/" + fDbXml)

        # gzip the wfu file
        subprocess.call(["gzip", "-9", DestCalcDir + "/" + fDbWfu])

        # now we are done, release
        con.commit()

      except sqlite3.Error, e:
         print e
         print "This is sqlite3 error, check consistency in data base"
         raise
      except IOError, e:
         print e
         print "IOError occured, possibily a file copying error."
         print "The data base has been modified"
         print "Check if files on dir are in sync with db"
         raise

   except sqlite3.Error, e:
      print e
      print "This is sqlite3 error; nothing has been copied to data base"
      raise

   except:
      print "Some error happened; data base has not been modified"
      raise

def ImportDirList(Args,Db,BaseDir,DirList,DataDir):
   """ This tries to import all calculations found in DirList into DataDir.
       Each directory in DirList is imported if possible.
       For the import to be successful, the .calc file must be present
       in that directory; only one .calc file must be present. """
   # first if each directory in DirList is readable
   DirCalcList = []
   for Dir in DirList:
      DirFull = BaseDir + "/" + Dir
      misc.CheckDirAccess(DirFull,bRead=True,bAssert=True)
      lfall = [ f for f in os.listdir(DirFull) ]
      lf = [ f for f in lfall if f.endswith(".calc") ]
      if len(lf) == 0:
         raise Exception("The directory " + DirFull + " has no .calc file")
      elif len(lf) > 1:
         raise Exception("The directory " + DirFull + " has " + len(lf) + " .calc files")
      else:
         # now there is only one calc file
         CalcFile = lf[0]
         base,extcalc = os.path.splitext(CalcFile)
         # check if all remaining files are physically present
         for ext in [".xyz",".wfu",".com",".out",".res",".pun",".xml"]:
            if not ((base + ext in lfall) and misc.CheckFileAccess(DirFull + "/" + base + ext,bRead=True,bAssert=False)):
               raise Exception("File " + base + ext + " is not found in " + DirFull)
         DirCalcList.append((DirFull,DirFull + "/" + CalcFile))

   # the DataDir should be writeable.
   misc.CheckDirAccess(DataDir,bRead=False,bAssert=True)

   # now we can import
   for (CalcDir,CalcFile) in DirCalcList:
      print "Importing ...",CalcDir,"...",
      ImportCalc(Db,CalcDir,CalcFile,DataDir,Verbose=Args.Verbose)
      print "done"

def ImportNearNbrJobs(Args):
    """ Import a nearest neighbour type of export job.
    
    Db        -- Data base file
    ExportDir -- The directory under which jobs and export.dat file is found.
                 The individual jobs will under this directory.
    DataDir   -- The base directory where imported data will be copied to.
                 For example "GeomData"
    ExportId  -- The export id -> must match one in export.dat file.
                 If it is 0, then it will be read from export.dat file.
    """
    Db = Args.DbMain
    ExportDir = Args.ExportDir
    DataDir = Args.PESDir
    ExportId = Args.ExportId

    # Db must have read as well as write access
    misc.CheckFileAccess(Db,bRead=True,bAssert=True)
    misc.CheckFileAccess(Db,bRead=False,bAssert=True)
   
    # ExportDir should have read access
    # DataDir should have write access
    misc.CheckDirAccess(ExportDir,bRead=True,bAssert=True)
    misc.CheckDirAccess(DataDir,bRead=False,bAssert=True)

    # If ExportId is not available, then it will be picked up from export.dat file
    if ExportId == 0:
       fExpDat = ExportDir + "/" + "export.dat"
       with open(fExpDat,'r') as f:
           sExpDat = f.read()
           f.close()
       dExpDat = ParseFile(sExpDat,['ExpId','CalcDirs'])
       ExportId = int(dExpDat['EXPID'])
   
    # open data base and obtain details of ExportId
    ImportGeomIdsDirsDb = []
    ExportsRow = None
    with sqlite3.connect(Db) as con:
        # use row factory which is far better and has dictionary-like access to data
        con.row_factory = sqlite3.Row
        cur = con.cursor()
        cur.execute('SELECT * FROM Exports WHERE Id=?',(ExportId,))
        exp_row = cur.fetchall()
        if exp_row:
            assert (len(exp_row) == 1)
            ExportsRow = exp_row[0]
        else:
            raise Exception("ExportId = " + str(ExportId) + " not found in data base")
        # first check if this export is "open" -- its an error to import a closed export
        if ExportsRow['Status'] != 0:
            raise Exception("Can not import. Export Id " + str(ExportId) + " is already closed.")

        # now obtain list of jobs which can be imported.
        cur.execute("SELECT GeomId,CalcDir FROM ExpCalc where ExpId=?",(ExportId,))
        expcalc_row = cur.fetchall()
        for row in expcalc_row:
            ImportGeomIdsDirsDb.append((row['GeomId'],row['CalcDir']))
            
    # if there are no calculations to be imported
    if not ImportGeomIdsDirsDb:
        raise Exception("There are no calculations to be imported. Please check Data base.")

    # now we have the list of geometries and directories to be imported - as per Db
    # we read export.dat file and confirm if everything is okay
    fExpDat = ExportDir + "/" + "export.dat"
    with open(fExpDat,'r') as f:
        sExpDat = f.read()
        f.close()
    dExpDat = ParseFile(sExpDat,['ExpId','CalcDirs'])
    # obtain a list of incomplete jobs
    # such jobs will not have corresponding .calc file, but .calc_ file
    CalcDirs = dExpDat['CALCDIRS'].split()
    CalcDirsDone = [d for d in CalcDirs if os.path.isfile(ExportDir + "/" + d + "/" + d + ".calc")]
    if Args.Verbose:
       if CalcDirsDone:
          print len(CalcDirsDone), " jobs can be imported out of total possible jobs ", len(CalcDirs)
       else:
          print "No importable jobs in directory", ExportDir
    
    # now we need to reconcile both these lists.
    # it might be that some calculations are already imported previously
    # it may also happen that all still remaining on db are being imported now.
    # we will now prepare a final list of directories to be imported
    CalcDirsToImport = []
    GeomIdsToImport = []
    for (g,d) in ImportGeomIdsDirsDb:
        if d in CalcDirsDone:
            CalcDirsToImport.append(d)
            GeomIdsToImport.append(g)
    assert (len(CalcDirsToImport) == len(GeomIdsToImport))

    if Args.Verbose:
       if CalcDirsToImport:
          print len(CalcDirsToImport), " jobs will be imported out of total importable jobs ", len(CalcDirsDone)
       else:
          print "No jobs will be imported from ", ExportDir

    # now import
    ImportDirList(Args,Db,ExportDir,CalcDirsToImport,DataDir)
    
    # now remove imported job from ExpCalc table in data base
    # update Exports table with imported list of geometries
    # if all geometries are imported, change the status
    with sqlite3.connect(Db) as con:
        # use row factory which is far better and has dictionary-like access to data
        con.row_factory = sqlite3.Row
        cur = con.cursor()
        for GeomId,CalcDir in zip(GeomIdsToImport,CalcDirsToImport):
            cur.execute('DELETE FROM ExpCalc WHERE ExpId=? AND GeomId=? AND CalcDir=?',(ExportId,GeomId,CalcDir))
        # update exports table using ExportsRow already available
        sImpGeomIds = ExportsRow['ImpGeomIds']
        if sImpGeomIds:
            # already some entry is there, append it
            sImpGeomIds += "," + ",".join([str(g) for g in GeomIdsToImport])
        else:
            # fresh entry
            sImpGeomIds = ",".join([str(g) for g in GeomIdsToImport])
        cur.execute("UPDATE Exports SET ImpDT=datetime('now','localtime'), ImpGeomIds=? WHERE Id=?",(sImpGeomIds,ExportId))
        # commit now
        con.commit()
        # if no geometries remain to be imported, change the status to closed
        cur.execute("SELECT * FROM ExpCalc where ExpId=?",(ExportId,))
        expcalc_row = cur.fetchall()
        if expcalc_row:
            # geometries remain to be imported
            print "Export with Id = " + str(ExportId) + " is not closed."
            pass
        else:
            # all have been imported
            cur.execute("UPDATE Exports SET Status=1 WHERE Id=?",(ExportId,))
            print "Export with Id = " + str(ExportId) + " is been closed."
        # all done with import
        con.commit()

    # done
    print str(len(CalcDirsToImport)) + " Jobs have been successfully imported."


def GetExpGeomNearNbr(Db,CalcTypeId,GidSingle=0,GidList=[],SidList=[],MaxGeom=50,NbrDepth=1,NbrDb="",ConstDb="",bIncludePath=False,Verbose=False):
   """ Returns a list of nearest neighbour geometries which can be exported.
       A list of (GeomId,CalcId) is returned where
          GeomId : geometry to be exported
          CalcId : the id in calc table which corresponds to nearnest neighbour of GeomId.
       This will return an empty list if it can not export.
       
       Algorithm:
       **********
       This tries to return, as far as possible, 'MaxGeom' geometries.
       Parameter NbrDepth controls how neighbour geometries are selected.
       
       If NbrDepth is 1/2/3, then NNId,NNId1,NNId2 fields of Db are used.
       Depth is increased upto (and not including) NbrDepth and for each
       value of Depth, the corresponding NNId field is used. As soon as
       target of MaxGeom is acheived, the search is stopped.
       
       If NbrDepth > 3, then NbrDb data base is used along with Db.
       Depth is increased from 3 upto NbrDepth-1 and for each value of Depth,
       all geometries at this depth are fetched from NbrTable table in NbrDb.
       Next Depth is attempted if target is not met.
       
       If NbrDepth <= 0, then a different algorithm is used. The NbrDb is opened
       and all geometries in NbrTable are tried in the increasing order of Dist field.
       The results should be qualitatively similar to earlier case.
       
       The flag bIncludePath forces pathological points to be included.
       It is imagined that this latter flag is used conservatively, starting with
       NbrDepth=1 and going up to 3.
       
       TODO: There is too much repeated code in here; needs to be shortened.
       
   """

   # misc.CheckFileAccess(Db,bRead=True,bAssert=True)
   with sqlite3.connect(Db) as con:

      con.row_factory=sqlite3.Row
      cur = con.cursor()

      # first collect list of geometries for which calculations have been done
      cur.execute("SELECT Id,GeomId FROM Calc WHERE CalcId=?",(CalcTypeId,))
      lrow = cur.fetchall()
      if lrow and len(lrow) < MaxGeom:
         raise Exception("Not enough number of completed calculations present in database")

      # create a list of geometry ids of completed calculations
      # create a dictionary mapping geometry id to calcid -- to be used later
      CalcGeomIds = []
      DictCalcId = {}
      for row in lrow:
         CalcGeomIds.append(row["GeomId"])
         DictCalcId[row["GeomId"]] = row["Id"]

      # sort CalcGeomIds list so that binary search can be done on it
      # this is important; linear search becomes pretty slow.
      CalcGeomIds.sort()

      # look into exports table and build a list of geometries which must be
      # excluded because they are already computed or already exported.
      # ExpCalc table keeps a list of geometries already exported.
      ExcludeGeomIds = []

      ExcludeGeomIds.extend(CalcGeomIds)
      # The implementation of default condition of not exporting pathological geoms
      # This is done by adding all pathological geoms in the 'ExcludeGeomIds' list
      if not bIncludePath:
         cur.execute("SELECT Id FROM Geometry WHERE tags LIKE '%path%'")
         lrow = cur.fetchall()
         PathGeomIds = []
         for row in lrow:
            PathGeomIds.append(row["Id"])
         ExcludeGeomIds.extend(PathGeomIds)

      cur.execute("SELECT * FROM Exports WHERE CalcType=?",(CalcTypeId,))
      lrow = cur.fetchall()
      for row in lrow:
         cur.execute("SELECT GeomId FROM ExpCalc WHERE ExpId=?",(row['Id'],))
         lgeom = cur.fetchall()
         for lg in lgeom:			   
            ExcludeGeomIds.append(lg['GeomId'])   

      # pathological cases can also be excluded if asked for.
      # TODO : I am not sure this option works -- needs to test it

      # Define a list of geometries which are problematic so that they are 
      # not exported. It is assumed that they are already removed from
      # the 'calc' table of the database.

#--------------------------------------------------------------------------------
      lPrblmGeomIds = []
#--------------------------------------------------------------------------------

      ExcludeGeomIds.extend(lPrblmGeomIds)

      # sort this list so that binary search can be done on it
      ExcludeGeomIds.sort()

      # initialize the list of geometries which can be exported
      # the corresponding list contains calcid of neighbour geometries
      ExpGeomIdList = []
      ExpCalcIdList = []

      # To be required if user provides a database constraint
      sConst = ""

      # If user provides GidSingle, merge it to GidList
      if GidSingle:
         GidList.append(GidSingle) 

      # If user provides some geometries without starids, the startids will be assigned with '-1'
      if len(SidList) < len(GidList):
         excess = len(GidList) - len(SidList)
         for i in range(excess):
             SidList.append(-1)
         
      # A dictionary is required to assign the geomids with the corresponding startids, if present
      DictStartId = {}
     
      # Initialize the list of eligible geomids to be exported that are provided by the user
      GidListNew = []

      # Only take those geomids from GidList which are not in the ExcludeGeomIds list
      for geom,start in zip(GidList,SidList):
          if geom not in ExcludeGeomIds:
             DictStartId[geom] = start
             GidListNew.append(geom)
          # If user provides geometries that are in the excludelist, then provide zero integers as entry so that the list GidListNew
          # remains filled 
          else:
             DictStartId[geom] = -1
             GidListNew.append(0)


      # for each depth up to 3, we search within Geometry table
      #for Depth in range(min(NbrDepth,3)):
      for Depth in range(3):
          
          # for current 'Depth', decide the NNId field in Geometry table
          NNIdField = "NNId"
          if Depth > 0:
              NNIdField += str(Depth)

          # Implementation of selected geomids export. For that we have added one 
          # argument in the definition 'GetExpGeomNearNbr', i.e. GidList
          if GidListNew:
             if ConstDb:
                sConst = " and (" + ConstDb + ")"
             cur.execute("SELECT Id,{0} FROM Geometry WHERE Id in (".format(NNIdField) + ",".join([str(i) for i in GidListNew]) + ")" + sConst)
             MaxGeom = len(cur.fetchall())
             cur.execute("SELECT Id,{0} FROM Geometry WHERE Id in (".format(NNIdField) + ",".join([str(i) for i in GidListNew]) + ")" + sConst)
          else:           
             if ConstDb:
                sConst = " where " + ConstDb
             # go through all geometries in the table
             cur.execute("SELECT Id,{0} FROM Geometry".format(NNIdField) + sConst)

          for GeomRow in cur:
            
            # check if target is achieved
            if len(ExpGeomIdList) == MaxGeom:
                break
            
            GeomId = GeomRow["Id"]

            # if user provides positive start id then the given start id will be used
	    # if user does not provide any start id then Nbrid will be used (negetive sid)
	    # if user provides zero start id then no neighbouring geometry will be used for
	    # the calculation of the corresponding geometry id
            if GidListNew:
               if DictStartId[GeomId] > 0:
                  NbrId = DictStartId[GeomId]
               elif DictStartId[GeomId] < 0:
                  NbrId = GeomRow[NNIdField]
               else:
	          NbrId = 0
            else: 
               NbrId = GeomRow[NNIdField]

            # skip if this geometry is in exclude list
            # this list is potentially large - hence binary search
            i = bisect.bisect_left(ExcludeGeomIds,GeomId)
            if i != len(ExcludeGeomIds) and ExcludeGeomIds[i] == GeomId:
                continue
            
            # skip if geometry is already included - it is a small list
            if GeomId in ExpGeomIdList:
                continue
            
            # find if its neighbouring geometry at this depth is done
            # binary search should get over in max log(58000,base=2) approx 16 iterations
            i = bisect.bisect_left(CalcGeomIds, NbrId)
            if i != len(CalcGeomIds) and CalcGeomIds[i] == NbrId:
                # the neighbouring geometry is in the list of done calcs.
                # push it to export list
                ExpGeomIdList.append(GeomId)
                ExpCalcIdList.append(DictCalcId[NbrId])

	    # if user does not want to use the neighbouring geometry, start id will be 0
            if not NbrId:
	        # this geometry is neither in ExcludeGeomIds list nor in ExpGeomIdList.
                ExpGeomIdList.append(GeomId)
                ExpCalcIdList.append(0)

          # check if target is achieved
          if len(ExpGeomIdList) == MaxGeom:
              break
        
      # it does not matter if target is met or not, just return if the search is closeby
      # a closeby search is that one which is within three shells of neighbourhood
      if NbrDepth in range(1,4):
         return zip(ExpGeomIdList,ExpCalcIdList)
          
      # reaching here means that NbrDepth is greater than 3
      # now we will use NbrTable in NbrDb to expand the search
      # TODO : the following loop can be merged with previous one.

      misc.CheckFileAccess(NbrDb,bRead=True,bAssert=True)
      with sqlite3.connect(NbrDb) as conNbr:
          
          conNbr.row_factory=sqlite3.Row
          curNbr = conNbr.cursor()
          
          for Depth in range(NbrDepth):

              # Implementation of selected geomids export. For that we have added one 
              # argument in the definition 'GetExpGeomNearNbr', i.e. GidList
              if GidListNew:
                 if ConstDb:
                    sConst = " and (" + ConstDb + ")"
                 cur.execute("SELECT Id FROM Geometry WHERE Id in (" + ",".join([str(i) for i in GidListNew]) + ")" + sConst)
                 MaxGeom = len(cur.fetchall())
                 cur.execute("SELECT Id FROM Geometry WHERE Id in (" + ",".join([str(i) for i in GidListNew]) + ")" + sConst)
              else:           
                 if ConstDb:
                    sConst = " where " + ConstDb
                 # go through all geometries in the table
                 cur.execute("SELECT Id FROM Geometry" + sConst)
             
              geomlist = []
              for GeomRow in cur:
                 geomlist.append(GeomRow["Id"]) 
 
              Query = "SELECT GeomId,NbrId FROM NbrTable WHERE GeomId in (" + ",".join([str(i) for i in geomlist]) +\
                      ")" + "and Depth = ?"
              curNbr.execute(Query,(Depth,))

              # now go through all such geometries and see if they can be exported
              for NbrRow in curNbr:
                  
                  # check if target is achieved
                  if len(ExpGeomIdList) == MaxGeom:
                      break
                  
                  GeomId = NbrRow["GeomId"]

                  # if user provides geomids along startids then startid will be used, otherwise nbrids will be used
                  if GidListNew:
                     if DictStartId[GeomId] > 0:
                        NbrId = DictStartId[GeomId]
                     else:
                        NbrId = NbrRow['NbrId']
                  else: 
                     NbrId = NbrRow['NbrId']

    
                  # skip if this geometry is in exclude list
                  # this list is potentially large - hence binary search
                  i = bisect.bisect_left(ExcludeGeomIds,GeomId)
                  if i != len(ExcludeGeomIds) and ExcludeGeomIds[i] == GeomId:
                      continue
                  
                  # skip if geometry is already included - it is a small list
                  if GeomId in ExpGeomIdList:
                      continue
                  
                  # find if its neighbouring geometry at this depth is done
                  # binary search should get over in max log(58000,base=2) approx 16 iterations
                  i = bisect.bisect_left(CalcGeomIds, NbrId)
                  if i != len(CalcGeomIds) and CalcGeomIds[i] == NbrId:
                      # the neighbouring geometry is in the list of done calcs.
                      # push it to export list
                      ExpGeomIdList.append(GeomId)
                      ExpCalcIdList.append(DictCalcId[NbrId])
                      
              # check if target is achieved
              if len(ExpGeomIdList) == MaxGeom:
                  break

      # it does not matter if target is met or not, just return if the search is finished
      if NbrDepth > 3:
         return zip(ExpGeomIdList,ExpCalcIdList)

      # reaching here means that NbrDepth <= 0
      # now we will try alternative algorithm
      # this may not work any better than previous one

      # now we will use NbrTable in NbrDb to expand the search
      # but in a different way based purely on Dist field
      misc.CheckFileAccess(NbrDb,bRead=True,bAssert=True)
      with sqlite3.connect(NbrDb) as conNbr:
          
          conNbr.row_factory=sqlite3.Row
          curNbr = conNbr.cursor()
          
          if GidListNew:
             if ConstDb:
                sConst = " and (" + ConstDb + ")"
             cur.execute("SELECT Id FROM Geometry WHERE Id in (" + ",".join([str(i) for i in GidListNew]) + ")" + sConst)
             MaxGeom = len(cur.fetchall())
             cur.execute("SELECT Id FROM Geometry WHERE Id in (" + ",".join([str(i) for i in GidListNew]) + ")" + sConst)
          else:           
             if ConstDb:
                sConst = " where " + ConstDb
             # go through all geometries in the table
             cur.execute("SELECT Id FROM Geometry" + sConst)
          
          geomlist = []
          for GeomRow in cur:
             geomlist.append(GeomRow["Id"]) 
 
          Query = "SELECT GeomId,NbrId FROM NbrTable WHERE GeomId in (" + ",".join([str(i) for i in geomlist]) +\
                  ")" + "ORDER BY Dist ASC"
          curNbr.execute(Query)

          # now go through all such geometries and see if they can be exported
          for NbrRow in curNbr:
              
              # check if target is achieved
              if len(ExpGeomIdList) == MaxGeom:
                  break
              
              GeomId = NbrRow["GeomId"]
             
              # if user provides geomids along startids then startid will be used, otherwise nbrids will be used
              if GidListNew:
                 if DictStartId[GeomId] > 0:
                    NbrId = DictStartId[GeomId]
                 else:
                    NbrId = NbrRow['NbrId']
              else: 
                 NbrId = NbrRow['NbrId']


              # skip if this geometry is in exclude list
              # this list is potentially large - hence binary search
              i = bisect.bisect_left(ExcludeGeomIds,GeomId)
              if i != len(ExcludeGeomIds) and ExcludeGeomIds[i] == GeomId:
                  continue
              
              # skip if geometry is already included - it is a small list
              if GeomId in ExpGeomIdList:
                  continue
              
              # find if its neighbouring geometry at this depth is done
              # binary search should get over in max log(58000,base=2) approx 16 iterations
              i = bisect.bisect_left(CalcGeomIds, NbrId)
              if i != len(CalcGeomIds) and CalcGeomIds[i] == NbrId:
                  # the neighbouring geometry is in the list of done calcs.
                  # push it to export list
                  ExpGeomIdList.append(GeomId)
                  ExpCalcIdList.append(DictCalcId[NbrId])
                  

      # it does not matter if target is met or not, just return
      return zip(ExpGeomIdList,ExpCalcIdList)


###############################################################################################
# The following definition in the code is added by Bijit:

def GetExpMrciNactJobs(Db,CalcTypeId,MaxGeom=50,ConstDb="",Verbose=False):
   """ Returns a list of geometries for MRCI or NACT calc- to be exported.
       A list of (GeomId,CalcId) is returned where
          GeomId : geometry to be exported
          CalcId : the id in calc table which corresponds to calc of calctypeid = 1 of the GeomId.
       This will return an empty list if it can not export.
   """

   misc.CheckFileAccess(Db,bRead=True,bAssert=True)
   with sqlite3.connect(Db) as con:

      con.row_factory=sqlite3.Row
      cur = con.cursor()

      # first collect list of geometries for which calculations have been done
      cur.execute("SELECT Id,GeomId FROM Calc WHERE CalcId=?",(CalcTypeId,))
      lrow = cur.fetchall()

      # create a list of geometry ids of completed calculations
      CalcGeomIds = []
      for row in lrow:
         CalcGeomIds.append(row["GeomId"])

      ExcludeGeomIds = []
      # sort CalcGeomIds list so that binary search can be done on it
      # this is important; linear search becomes pretty slow.
      CalcGeomIds.sort()
      ExcludeGeomIds.extend(CalcGeomIds)

      # look into exports table and build a list of geometries which must be
      # excluded because they are already computed or already exported.
      # ExpCalc table keeps a list of geometries already exported.
      cur.execute("SELECT * FROM Exports WHERE CalcType=?",(CalcTypeId,))
      lrow = cur.fetchall()
      for row in lrow:
         cur.execute("SELECT GeomId FROM ExpCalc WHERE ExpId=?",(row['Id'],))
         lgeom = cur.fetchall()
         for lg in lgeom:			   
            ExcludeGeomIds.append(lg['GeomId'])   

      # Define a list of geometries which are problematic so that they are 
      # not exported. It is assumed that they are already removed from
      # the 'calc' table of the database.
      lPrblmGeomIds = []

      if CalcTypeId == 2:    # only to be seen for MRCI jobs
         ExcludeGeomIds.extend(lPrblmGeomIds)
   
      # sort this list so that binary search can be done on it
      ExcludeGeomIds.sort()


      if ConstDb:
         sConst = " where " + ConstDb
      else:
         sConst = ""

      cur.execute("SELECT Id FROM Geometry" + sConst)
      lgeomcon = cur.fetchall()

      ConstGeomIds = []
      for lg in lgeomcon:
          ConstGeomIds.append(lg['Id'])

      ConstGeomIds.sort()

      # initialize the the list of geometries which can be exported
      # the corresponding list contains calcid of the same geoms of calc-id = 1
      ExpGeomIdList = []
      ExpCalcIdList = []

      cur.execute("SELECT Id,GeomId FROM Calc WHERE CalcId = 1")
      row = cur.fetchone()
      while row:
         GeomId = row["GeomId"]
	 StartId = row["Id"]

	 # the geomid must not be in the exclude list
         if GeomId not in ExcludeGeomIds and GeomId in ConstGeomIds:
	    ExpGeomIdList.append(GeomId)
	    ExpCalcIdList.append(StartId)

         # fetch next one
         row = cur.fetchone()
         if len(ExpGeomIdList) == MaxGeom:
            # exit if max jobs is reached
            break

      return zip(ExpGeomIdList,ExpCalcIdList)

############################### Modified portion ends here! ###################################
###############################################################################################


def ExportCalc(Db,GeomId,CalcTypeId,DataDir,ExpDir,ComTemplate="",StartId=0,BaseSuffix="",Verbose=False):
   """ Export a calculation for geometry and produce the files required for calculation.
       This routine is supposed to be a low-level version and does not modify database.
       It uses data base in order to access or copy the data required for export.

     Db           -- The data base file
     GeomId       -- Id of geometry to be exported (in the Geometry table)
     CalcTypeId   -- Id of type of calculation to be exported (in the CalcInfo table)
     DataDir      -- The base directory where data is availble -- must be passed in
     ExpDir       -- The directory in which a sub-directory for this calc is to be created and files are be placed.
     ComTemplate  -- Template file to be used for export; if empty, then default is used.
     StartId      -- If non-zero, it is Id (in Calc table) of another already existing calculation.
                     The wfu file from this calculation copied and its name changed appropriately.
                     The input file generated will have orbital record from the copied wfu file.
                     NOTE : This can be used for to start from
                        * a completed calculation at a neighbouring geometry of this geometry.
                        * another completed calculation at this geometry.
   """
   # # first do some sanity checks before we export.
   # misc.CheckDirAccess(DataDir,bRead=True,bAssert=True)
   # misc.CheckDirAccess(ExpDir,bRead=False,bAssert=True)
   # misc.CheckFileAccess(Db,bRead=True,bAssert=True)

   # the given geometry must exist in the Geometry table
   # the calculation must be defined in the CalcInfo table.
   # assert (GeomId)
   # assert (CalcTypeId)
   with sqlite3.connect(Db) as con:

      # use row factory which is far better and has dictionary-like access to data
      con.row_factory = sqlite3.Row
      cur = con.cursor()

      # GeomId and CalcTypeId check
      cur.execute('SELECT * from Geometry WHERE Id=?',(GeomId,))
      geom_row = cur.fetchall()
      # assert (len(geom_row) == 1)
      cur.execute('SELECT * from CalcInfo WHERE Id=?',(CalcTypeId,))
      info_row = cur.fetchall()
      # assert (len(info_row) == 1)
      # extract details of this geometry and calculation, we will need them later
      GeomRow = geom_row[0]
      InfoRow = info_row[0]

      # now on, we will make it an error to export something already present in Calc table
      # TODO: change this to allow some flexibility to repeat a calculation.
      cur.execute('SELECT * from Calc WHERE GeomId=? AND CalcId=?',(GeomId,CalcTypeId))
      if cur.fetchall():
         # non-zero records, this calculation already exists.
         raise Exception("Error: The calculation of type CalcTypeId=%r on GeomId=%r already exists" % (CalcTypeId,GeomId))

      # if the calculation is declared to be dependent on another calculation type
      # make sure the that calculation results are available on the data base.
      # otherwise no point in exporting -- is there a point doing mrci which depends on some multi
      CalcTypeIdDep = InfoRow["Depends"]
      if CalcTypeIdDep:
         # check the CalcInfo table for details of this calculation type
         cur.execute("SELECT * from CalcInfo WHERE Id=?",(CalcTypeIdDep,))
         irow = cur.fetchall()
         if len(irow) == 1:
            # now check if there is calculation of this type on this geometry in Calc table
            cur.execute("SELECT * from Calc WHERE GeomId=? AND CalcId=?",(GeomId,CalcTypeIdDep))
            crow = cur.fetchall()
            if len(crow) == 0:
               # the calculation is not available, raise exeception
               raise Exception("This calculation depends on CalcId=%r which does not exist in Calc table" % (CalcTypeIdDep,))
            else:
               # there must be exactly one such calculation -- just to make sure
               assert(len(crow) == 1)
         else:
            # invalid CalcTypeIdDep provided -- this is error in config file supplied
            raise Exception("Invalid CalcId for Depends field -- check config file for this calc type")
      # now dependency conditions are met.

      # now prepare for generating the calc file
      CalcName = InfoRow["Name"]
      if ComTemplate:
         with open(ComTemplate,'r') as f:
           InpTempl = f.read()
         f.close()
      else:
         InpTempl = InfoRow["InpTempl"]
      Record = InfoRow["OrbRec"]
      Desc = "" # Desc in CalcInfo is not relevant
      Aux = ""

      # if StartId is non-zero, then it must exist in Calc table.
      # we gather details necessary for setting up such input
      # we need:
      #    wfn file of calculation
      #    the record number of orbitals
      bUnzip = False
      if StartId:
         cur.execute('SELECT * from Calc WHERE Id=?',(StartId,))
         start_row = cur.fetchall()
         assert (len(start_row) == 1)
         StartCalcRow = start_row[0]
         # pickup details from here -- needed for completing template file
         StartGId = StartCalcRow["GeomId"]
         StartDir = DataDir + "/" + StartCalcRow["Dir"]
         StartWfnFile = StartCalcRow["WfnFile"]
         StartRecord = StartCalcRow["OrbRec"]
         # check access for wave-function -- it could be a zip file
         misc.CheckDirAccess(StartDir,bRead=True,bAssert=True)
         if misc.CheckFileAccess(StartDir + "/" + StartWfnFile,bRead=True,bAssert=False):
            bUnzip = False
         elif misc.CheckFileAccess(StartDir + "/" + StartWfnFile + ".gz",bRead=True,bAssert=False):
            bUnzip = True
         else:
            raise Exception("Wavefunction file=%r does not exist" %(StartWfnFile,))
      else:
          StartGId = 0


      # decide basename needed for generated files
      # we can use a combination of geometry and calculation name to be sure
      # basename = CalcType + CalcId + "-" + "geom" + GeomId
      # this works out something like "multi2-geom1" .. should be fine I think.
      # TODO: do this optimally if these turn out to be too difficult to navigate.
      BaseName = InfoRow["Type"] + str(CalcTypeId) + "-" + "geom" + str(GeomId)
      if BaseSuffix:
         BaseName = BaseName + "-" + BaseSuffix

      # create required directory
      ExportDir = ExpDir + "/" + BaseName
      os.mkdir(ExportDir,0775)

      # now we are ready to generate files, first calc and xyz files
      sCalcFile = GenCalcFile(CalcTypeId,GeomId,CalcName,Record,BaseName,Desc="",Aux="Start GId - " + str(StartGId))
      GeomObj = geometry.Geometry(GeomRow["sr"],GeomRow["cr"],GeomRow["theta"],id=GeomId)
      sXYZFile = GeomObj.to_xyzstr()

      # write them out
      # for calc file, we will generate it as .calc_ <--- note extra underscore at end
      # this is to safegaurd against faulty imports.
      # this should be renamed to .calc upon successful run
      fCalc = ExportDir + "/" + BaseName + ".calc_"  # <-- extra underscore
      fXYZ  = ExportDir + "/" + BaseName + ".xyz"
      with open(fCalc,'w') as f:
         f.write(sCalcFile)
         f.close()
      with open(fXYZ,'w') as f:
         f.write(sXYZFile)
         f.close()

      # if wfn file needs to be copied from elsewhere, do that now
      if StartId:
         fSrcWfn = StartDir + "/" + StartWfnFile # this has .wfu extension already
         fDstWfn = ExportDir + "/" + BaseName + ".wfu"
         if bUnzip:
            fSrcWfn += ".gz"
            fDstWfn += ".gz"
         shutil.copy(fSrcWfn,fDstWfn)
         if bUnzip:
            subprocess.call(["gzip", "-d", fDstWfn])
            
      # now input file -- apply replacement substitutions to template string
      s0 = InpTempl.replace("$F$",BaseName)
      s1 = s0.replace("$R$",Record)
      # $S$ may not exist in all files
      if s1.count("$S$"):
         # substitute with starting record if asked for
         if StartId:
            sInpFile = s1.replace("$S$",StartRecord)
         else:
            sInpFile = s1
            print "WARNING: template not fully substituted -- check input file"
      else:
         sInpFile = s1
      # generate input file
      fInp = ExportDir + "/" + BaseName + ".com" # we have decided to generate .com and not .inp
      with open(fInp,'w') as f:
         f.write(sInpFile)
         f.close()

      # done with exporting
      # we will return base name to the calling routine
      if Verbose:
         print "\tJob for GeomId=",GeomId," exported to", ExportDir
      return BaseName

def ExportGeometries(Args,ExportList,ExpDir):
   """ this exports a list of geometries to separate directories """


   ExportedDirs = []
   for (GeomId,StartCalcId,BaseSuffix) in ExportList:
      BaseName = ExportCalc(Args.DbMain,GeomId,Args.CalcTypeId,Args.PESDir,ExpDir,
                            ComTemplate=Args.ComTemplate,StartId=StartCalcId,
                            BaseSuffix=BaseSuffix,Verbose=Args.Verbose)
      # collect list of base names exported
      ExportedDirs.append(BaseName)

   # done, return list of exported directories for later processing
   # if Args.Verbose:
   #    print
   #    print "\tA total of ",len(ExportedDirs)," geometries has been exported to jobs in ",ExpDir
   return ExportedDirs

sRunJobPythonFilePrefix = r'''#!/usr/bin/python
# -*- coding: utf-8 -*-

import os
import os.path
import shutil
import subprocess
import time

""" A context manager to run molpro jobs in some directory """
from contextlib import contextmanager

@contextmanager
def cd(newdir):
    prevdir = os.getcwd()
    os.chdir(os.path.expanduser(newdir))
    try:
        yield
    finally:
        os.chdir(prevdir)

def RunMolpro(RunDir,ScrDir,ComFile):
   """ This runs molpro file 'ComFile' located in RunDir. """
   with cd(RunDir):
         exitcode = subprocess.call(["molpro", "-d", ScrDir, "-W .", "-n","2", ComFile])
      return exitcode

def ParseFile(sfile,lkeys):
   """ A generic parser which can parse key : value pairs from any string and return a dictionary of parsed options """
   def remove_comments(s):
       p = s.find("#")
       if p >=0:
          snew = s[0:p]
       else:
          snew = s
       return snew.strip()
   ls0 = [x.strip() for x in sfile.splitlines() if x.strip()]
   ls1 = [tuple(x.split(":")) for x in ls0 if remove_comments(x)]
   for t in ls1:
      assert (len(t) == 2)
   ls2 = [(x.strip(),y.strip()) for (x,y) in ls1]
   lparse = { k.upper():v for (k,v) in ls2 }
   for key in lkeys:
      assert( key.upper() in lparse )
   assert (len(lparse) == len(lkeys))
   return lparse

def RunExportedCalcs(MolproScrDir):
   """ Run or continue a series of exported jobs."""

   fExpDat = "export.dat";
   fRunLog = "run.log";

   # first open export.dat file and collect information about exported jobs
   with open(fExpDat,'r') as f:
      sExpDat = f.read()
      f.close()
   dExpDat = ParseFile(sExpDat,['ExpId','CalcDirs'])

   # obtain a list of incomplete jobs
   # such jobs will not have corresponding .calc file, but .calc_ file
   CalcDirs = dExpDat['CALCDIRS'].split()
   DirsDone = [d for d in CalcDirs if os.path.isfile(d+"/"+d+".calc")]
   DirsToDo = [d for d in CalcDirs if os.path.isfile(d+"/"+d+".calc_")]
   if len(CalcDirs) != len(DirsDone) + len(DirsToDo):
      raise Exception("Some dirs in this export directory = " + os.getcwd() + " seem to not have .calc/.calc_ file.")

   # Before we run, indicate run details into Log file.
   # open log file in append mode
   fLog = open(fRunLog,"a")
   fLog.write(100*"*"+"\n")
   fLog.write(30*" " + time.asctime(time.localtime())+"\n")
   fLog.write(100*"*"+"\n")
   fLog.write("\n")
   for d in DirsDone:
      fLog.write("Skipping already compelted job Dir " + d + "\n")
   fLog.flush()
   os.fsync(fLog)

   # now execute each job
   for RunDir in DirsToDo:

      # job will be now done
      fLog.write("Begin Job " + RunDir + " on " + time.asctime(time.localtime()) + "\n")
      fLog.flush()
      os.fsync(fLog)

      ScrDirCalc = os.path.expanduser(MolproScrDir + "/" + "scr-" + RunDir)
      os.mkdir(ScrDirCalc,0775)
      fComBaseFile = RunDir + ".com"

      exitcode = RunMolpro(RunDir,ScrDirCalc,fComBaseFile)

      if exitcode == 0:

         # molpro has run successfully, update log
         fLog.write("   Completed on " + time.asctime(time.localtime()) + "\n")
         fLog.write("\n")
         fLog.flush()
         os.fsync(fLog)

         # rename .calc_ file so that it can be imported
         os.rename(RunDir + "/" + RunDir + ".calc_", RunDir + "/" + RunDir + ".calc")

      else:

         # molpro has not run successfully, indicate it
         fLog.write("   JOB UNSUCCESSFUL ON " + time.asctime(time.localtime()) + "\n")
         fLog.write("\n")
         fLog.flush()
         os.fsync(fLog)

      # remove scratch directory
      subprocess.call(["rm","-rf",ScrDirCalc])

   # finish and close log file     
   fLog.write("Run of Exported Calcs Completed on " + time.asctime(time.localtime()))
   fLog.write("\n")
   fLog.write(100*"*"+"\n")
   fLog.write("\n")
   fLog.write("\n")
   fLog.flush()
   os.fsync(fLog)
   fLog.close()
   
if __name__ == '__main__':

   # define molpro scratch, this will be properly expanded during runtime
   MolproScrDir = "~/MOLPRO_SCRATCH"
   #MolproScrDir = "/tmp/bijit"
   
   # now run jobs
   RunExportedCalcs(MolproScrDir)

'''

def ExportNearNbrJobs(Args):
   """ Export a number of Jobs. This one is the general export.
       Algorithm is described in GetExpGeomNearNbr function.
       Parameters are also described there.
   """

   # ExportDir should have write access
   # misc.CheckDirAccess(Args.ExportDir,bRead=False,bAssert=True)

   # first obtain a list of geometries to be exported
   # assert (Args.CalcTypeId)

   # To export MRCI geometries, the following if-else is added:
   # CalcId = 2 corresponds to MRCI (this should be correct otherwise error will return)
   if Args.CalcTypeId > 1:

      ExpGeomList = GetExpMrciNactJobs(Args.DbMain,Args.CalcTypeId,
              MaxGeom=Args.NumJobs,ConstDb=Args.ConstDb,Verbose=Args.Verbose)

   else:
      ExpGeomList = GetExpGeomNearNbr(Args.DbMain,Args.CalcTypeId,Args.GeomId,Args.GeomIdList,
              Args.StartIdList,MaxGeom=Args.NumJobs,NbrDepth=Args.Depth,NbrDb=Args.DbNbr,
              ConstDb=Args.ConstDb,bIncludePath=Args.IncludePath,Verbose=Args.Verbose)


   # we will make sure all the data for export is available before initiating the export
   # misc.CheckDirAccess(Args.PESDir,bRead=True,bAssert=True)
   with sqlite3.connect(Args.DbMain) as con:
      
      con.row_factory=sqlite3.Row
      cur = con.cursor()
      
      # first find info about this calculation type
      cur.execute('SELECT * from CalcInfo WHERE Id=?',(Args.CalcTypeId,))
      info_row = cur.fetchall()
      # assert (len(info_row) == 1)
      InfoRow = info_row[0]
      # extract details about all calculations referred in list of exported geometries
      cur.execute("SELECT * FROM Calc WHERE Id in (" + ",".join([str(y) for x,y in ExpGeomList]) + ")")
      # this hack isnt recommended in sqlite3  -----> ^^^^^^^^^^^^
      lrow = cur.fetchall()
      #? removing it for now
      # for row in lrow:
      #    Dir = Args.PESDir+"/"+row['dir']
         # misc.CheckDirAccess(Dir,bRead=True,bAssert=True)
         # wave-function file -- it may be in gzip form
         # if misc.CheckFileAccess(Dir+"/"+row['WfnFile'],bRead=True,bAssert=False):
            # file is there in uncompressed form
            # pass
         # elif misc.CheckFileAccess(Dir+"/"+row['WfnFile']+".gz",bRead=True,bAssert=False):
            # file is in compressed form
            # pass
         # else:
            # file is not there
            # raise Exception("WfnFile = " + row['WfnFile'] + " is not available for export.")
         # the orbital record must be meaningful
         # assert(row['OrbRec'])

      # now we export -- things perhaps wont fail now
      # first insert a new row into Exports Table and get its id
      cur.execute("INSERT INTO Exports (Type,CalcType) VALUES (?,?)", (0,Args.CalcTypeId))
      ExportId = cur.lastrowid

      # create a subdir under ExpDir where the current export data goes
      # ExpDir = Args.ExportDir + "/" + "Export" + str(ExportId) + "-" + InfoRow['type'] + str(Args.CalcTypeId)
      # os.mkdir(ExpDir,0775)

      #* **********
      ExpDir = "{}/Export{}-{}{}".format(Args.ExportDir, ExportId, InfoRow[0], Args.CalcTypeId)
      os.makedirs(ExpDir)

      # prepare a list of geometries to be exported with suffix
      ExpGeomListSuffix = []
      nExp = len(ExpGeomList)
     
     #! why is this needed?
      for i in range(len(ExpGeomList)):
         s = str(i+1)
         ExpGeomListSuffix.append(ExpGeomList[i]+(s,)) # <- tuple addition here


      # now export all geometries, this will create all subdirectories
      ExportedDirList = ExportGeometries(Args,ExpGeomListSuffix,ExpDir)

      # if this is successful, then we need to update the Exports table
      cur.execute("UPDATE Exports SET Type=0, NumCalc=?, ExpDir=?, ExpDT=datetime('now','localtime') WHERE Id=?",\
                   (len(ExportedDirList),os.path.abspath(ExpDir),ExportId))

      # we will also need to enter exported geometries in ExpCalc table
      # assert(len(ExportedDirList) == len(ExpGeomListSuffix))
      lexpcalc = []
      for i in range(len(ExportedDirList)):
         lexpcalc.append((ExportId,ExpGeomListSuffix[i][0],ExportedDirList[i]))

      cur.executemany("INSERT INTO ExpCalc (ExpId,GeomId,CalcDir) VALUES (?,?,?)",lexpcalc)

      # commit the changes      
      # con.commit()

      # now, we are almost done!
      # we need to generate remaining files
      fExportDat = ExpDir + "/" + "export.dat"
      with open(fExportDat,'w') as f:
         f.write("# Auto generated file. Please do not modify\n")
         f.write("ExpId : " + str(ExportId))
         f.write("\n")
         f.write("CalcDirs : " + " ".join(ExportedDirList))
         f.write("\n")
         f.close()
      # change mode of this file to read-only to prevent accidental writes
      os.chmod(fExportDat,0444)

      # if Args.Verbose:
      #    print "Export with ExportId =", ExportId, " has been entered into data base ", Args.DbMain

      # the python file needs to be generated
      fPythonFile = ExpDir + "/" + "RunJob" + str(ExportId) + ".py"
      with open(fPythonFile,'w') as f:
         f.write(sRunJobPythonFilePrefix)
         f.write("\n")
         f.close()

      # if Args.Verbose:
      #    print "Use Python file ", fPythonFile, "to run the generated jobs."

      # chmod to executable
      # os.chmod(fPythonFile,0766)

# def CloseExport(Db,ExportId,Verbose=False):
#     """ Close an export which is still open; expunge all its remaining jobs.
#         This can be used when the export is no longer required to be open.
#     """
#     # now remove imported job from ExpCalc table in data base
#     # update Exports table with imported list of geometries
#     # if all geometries are imported, change the status
#     with sqlite3.connect(Db) as con:
#         # use row factory which is far better and has dictionary-like access to data
#         con.row_factory = sqlite3.Row
#         cur = con.cursor()
#         # obtain details of export to be closed
#         cur.execute('SELECT * FROM Exports WHERE Id=?',(ExportId,))
#         exp_row = cur.fetchall()
#         ExpInfo = None
#         if exp_row:
#             assert (len(exp_row) == 1)
#             ExpInfo = exp_row[0]
#         else:
#             raise Exception("ExportId = " + str(ExportId) + " not found in data base")           
#         # also check if this export is "open"
#         if ExpInfo['Status'] != 0:
#             raise Exception("Can not close. Export Id " + str(ExportId) + " is already closed.")
#         # now expunge all pending jobs of this export
#         cur.execute('DELETE FROM ExpCalc WHERE ExpId=?',(ExportId,))
#         # now set the status to indicate closure
#         cur.execute("UPDATE Exports SET Status=1 WHERE Id=?",(ExportId,))
#         # all done
#         con.commit()
#         if Verbose:
#            print "Export " + str(ExportId) + " has been successfully closed."

if __name__ == "__main__":

    pass
